{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "590f3899dd7b9bcfd4cbc68d67e174e21f00fe45394f2e3932fd522000967c3f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import numba\n",
    "import os\n",
    "import re\n",
    "\n",
    "from getIg import getZ\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_get_text(cell):\n",
    "    return cell.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@numba.jit\n",
    "def process_radiation_search(download_path):\n",
    "    html_file = open(download_path, \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    table = soup.find_all(\"table\")[0]\n",
    "    gammas = table.find_all(\"tr\")\n",
    "    init_dict = {\"E_tab\": [0], \"Ig\": [0], \"Decay_Mode\": [\"b-\"], \"half_life\": [\"3 m\"], \"Isotope\": [\"Tu\"]}\n",
    "    gamma_df = pd.DataFrame(init_dict)\n",
    "\n",
    "    for gamma_row in gammas[2:-2]:\n",
    "        vals = list(map(func_get_text, gamma_row.find_all(\"td\")))\n",
    "        try:\n",
    "            gamma_df = gamma_df.append({\"E_tab\": vals[0].split()[0], \"Ig\": vals[1].split()[0], \"Decay_Mode\": vals[2], \"half_life\": vals[3], \"Isotope\": vals[4]}, ignore_index=True)\n",
    "        except:\n",
    "            print(\"******* MISSING INTENSITY **************\")\n",
    "            #print(vals)\n",
    "            continue\n",
    "    return gamma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gammas(energy, fwhm, t_min, t_max):\n",
    "    print(energy)\n",
    "    e_min = energy - fwhm\n",
    "    e_max = energy + fwhm\n",
    "    output_file = f\"downloads/searchE{energy}pm{fwhm}tMin{t_min}tMax{t_max}.html\"\n",
    "    if not os.path.isfile(output_file):\n",
    "        request_url = f\"http://nucleardata.nuclear.lu.se/toi/Gamma.asp?sql=&Min={e_min}&Max={e_max}&HlifeMin={t_min}&tMinStr={t_min}+s&HlifeMax={t_max}&tMaxStr={t_max}+s\"\n",
    "        urllib.request.urlretrieve(request_url, output_file)\n",
    "        print(f\"File {output_file} downloaded.\")\n",
    "    \n",
    "    gamma_df = process_radiation_search(output_file)\n",
    "    gamma_df[\"Energy\"] = energy\n",
    "    gamma_df[\"FWHM\"] = fwhm\n",
    "    gamma_df[\"half_life_searched\"] = f\"{t_min} - {t_max}\"\n",
    "    gamma_df = gamma_df.drop([0])\n",
    "    return gamma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_star(some_string):\n",
    "    if \"*\" in str(some_string) or \"~\" in str(some_string) or \"<\" in str(some_string) or \">\" in str(some_string):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_gammas(df, t_min, t_max, e_thr):\n",
    "    df[\"Ig\"] = int(1000.1)\n",
    "    for row in df.iterrows():\n",
    "        possible_gammas = find_gammas(row[1][\"Energy\"], row[1][\"FWHM\"], t_min, t_max)\n",
    "        df = df.append(possible_gammas, ignore_index=True)\n",
    "    #print(f\"DF size is {df.shape}\")\n",
    "    drop_columns = [\n",
    "        \"Fit\", \"Filename\", \"Sample Identification\", \n",
    "        \"Sample Type\", \"Sample Geometry\", \n",
    "        \"Sample Size\", \"Efficiency ID\", \n",
    "        \"Peak Analysis Report                    2.12.2020  10\"\n",
    "        ]\n",
    "    drop_columns3 = [\"Peak Analysis From Channel\", \"Peak Search Sensitivity\", \"Max Iterations\"]\n",
    "    drop_columns4 = [\"Use Fixed FWHM\", \"Peak Fit Engine Name\"]\n",
    "    df = df.drop(columns=drop_columns)\n",
    "    #df = df.drop(columns=drop_columns2)\n",
    "    df = df.drop(columns=drop_columns3)\n",
    "    df = df.drop(columns=drop_columns4)\n",
    "    print(df.columns)\n",
    "\n",
    "    # change columns order\n",
    "    old_column_order = df.columns.tolist()\n",
    "    first_cols = [\"Energy\", \"FWHM\", \"E_tab\", \"Area\", \"%err\", \"Ig\", \"half_life\", \"Isotope\", \"Real Time\", \"Live Time\"]\n",
    "    new_cols = first_cols + list(set(old_column_order) - set(first_cols))\n",
    "    df = df[new_cols]\n",
    "    df[\"Real Time\"] = df[\"Real Time\"].apply(lambda x: float(str(x).split(' ')[0]))\n",
    "    df[\"Live Time\"] = df[\"Live Time\"].apply(lambda x: float(str(x).split(' ')[0]))\n",
    "    #df = df[df[\"Ig\"].apply(lambda x: str(x).isnumeric())]\n",
    "    #df[\"Ig\"] = pd.to_numeric(df['Ig'], errors='coerce')\n",
    "\n",
    "    \n",
    "    df = df[df[\"Ig\"] != \"*\"]\n",
    "    df = df[df[\"Ig\"] != \"\"]\n",
    "\n",
    "    df[\"Has_star\"] = df[\"Ig\"].apply(has_star)\n",
    "    df = df[df[\"Has_star\"] == 0]\n",
    "\n",
    "    #df[\"Ig\"] = df[\"Ig\"].apply(float(re.findall(r\"[\\d\\.\\d]+\", str(x))[0]))\n",
    "\n",
    "    df['Ig'] = df['Ig'].astype(float)\n",
    "    df = df[df[\"Ig\"] >= e_thr]\n",
    "\n",
    "    df = df.sort_values(by=[\"Energy\", \"Ig\"], ascending=[True, False])\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_origin(df, origins_dict):\n",
    "    for row in df.iterrows():\n",
    "        row[\"Origin\"], origins_dict = find_origin(row[\"Isotope\"], origins_dict)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_origin(isotope, origin_dict):\n",
    "    try:\n",
    "        return origin_dict.get(isotope), origin_dict\n",
    "    except KeyError:\n",
    "        return add_isotope_origin(isotope, origin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_isotope_origin(isotope, origin_dict):\n",
    "    A, metastable, element = re.split(r'(\\d{2,3})(m{0,1}\\d{0,1})(\\w+)', isotope)[1:-1]\n",
    "    \n",
    "    if metastable == \"m\":\n",
    "        A += 300\n",
    "    elif metastable == \"m2\":\n",
    "        A += 600\n",
    "    url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={getZ(element)}0{A}\"\n",
    "    download_path = \"downloads/temp.html\"\n",
    "    urllib.request.urlretrieve(url, download_path)\n",
    "    html_file = open(download_path, \"r\")\n",
    "    table = BeautifulSoap(html_file.read(), 'lxml').find_all(\"table\")[1]\n",
    "    try:\n",
    "        origin_dict[isotope] = table.find_all(\"tr\")[7].find(\"td\").get_text(strip=True)\n",
    "    except:\n",
    "        origin_dict[isotope] = \"???\"\n",
    "\n",
    "    return origin_dict.get(isotope), origin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25.27\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "79.8\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "95.02\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "114.9\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "150.05\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "181.23\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "196.63\n",
      "******* MISSING INTENSITY **************\n",
      "201.52\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "210.86\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "277.78\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "312.28\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "317.01\n",
      "******* MISSING INTENSITY **************\n",
      "343.88\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "358.08\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "396.63\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "402.73\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "407.89\n",
      "******* MISSING INTENSITY **************\n",
      "435.0\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "467.57\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "506.03\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "530.59\n",
      "535.04\n",
      "******* MISSING INTENSITY **************\n",
      "566.02\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "590.45\n",
      "621.4\n",
      "631.39\n",
      "641.21\n",
      "******* MISSING INTENSITY **************\n",
      "647.68\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "748.33\n",
      "767.06\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "793.31\n",
      "******* MISSING INTENSITY **************\n",
      "812.67\n",
      "818.8\n",
      "857.18\n",
      "******* MISSING INTENSITY **************\n",
      "894.59\n",
      "912.45\n",
      "918.6\n",
      "933.13\n",
      "953.43\n",
      "******* MISSING INTENSITY **************\n",
      "963.92\n",
      "1031.83\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "1078.51\n",
      "1204.41\n",
      "1248.19\n",
      "******* MISSING INTENSITY **************\n",
      "1323.87\n",
      "1384.16\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "1436.06\n",
      "1525.13\n",
      "******* MISSING INTENSITY **************\n",
      "******* MISSING INTENSITY **************\n",
      "1678.3\n",
      "1768.85\n",
      "2016.86\n",
      "******* MISSING INTENSITY **************\n",
      "2219.41\n",
      "2393.78\n",
      "2571.99\n",
      "2641.65\n",
      "Index(['Pk', 'IT', 'Energy', 'Area', 'Bkgnd', 'FWHM', 'Channel', 'Left', 'PW',\n",
      "       'Cts/Sec', '%err', 'Report Generated On', 'Peak Locate Threshold',\n",
      "       'Peak Locate Range (in channels)', 'Peak Area Range (in channels)',\n",
      "       'Identification Energy Tolerance', 'Sample Taken On',\n",
      "       'Acquisition Started', 'Live Time', 'Real Time', 'Dead Time',\n",
      "       'Energy Calibration Used Done On',\n",
      "       'Efficiency Calibration Used Done On', 'Peak Analysis Performed on',\n",
      "       'Ig', 'E_tab', 'Decay_Mode', 'half_life', 'Isotope',\n",
      "       'half_life_searched'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"parsed_reports/M1-C1-Udepl-120.csv\", index_col=0)\n",
    "all_gammas = add_all_gammas(df, 120, 1e5, 1e-2)\n",
    "\n",
    "all_gammas.to_csv(\"out/M1-C1-Udepl-120.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"parsed_reports/M6-C1-Udepl-3.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     86795.1\n",
       "1     86795.1\n",
       "2     86795.1\n",
       "3     86795.1\n",
       "4     86795.1\n",
       "       ...   \n",
       "81    86795.1\n",
       "82    86795.1\n",
       "83    86795.1\n",
       "84    86795.1\n",
       "85    86795.1\n",
       "Name: Live Time, Length: 86, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 394
    }
   ],
   "source": [
    "df[\"Live Time\"].apply(lambda x: float(str(x).split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Pk, IT, Energy, Area, Bkgnd, FWHM, Channel, Left, PW, Cts/Sec, %err, Fit, Filename, Report Generated On, Sample Identification, Sample Type, Sample Geometry, Peak Locate Threshold, Peak Locate Range (in channels), Peak Area Range (in channels), Identification Energy Tolerance, Sample Size, Sample Taken On, Acquisition Started, Live Time, Real Time, Dead Time, Energy Calibration Used Done On, Efficiency Calibration Used Done On, Efficiency ID, Peak Analysis Report                    10.12.2020  8, Peak Analysis Performed on, Peak Analysis From Channel, Peak Search Sensitivity, Max Iterations, Use Fixed FWHM, Peak Fit Engine Name]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 37 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pk</th>\n      <th>IT</th>\n      <th>Energy</th>\n      <th>Area</th>\n      <th>Bkgnd</th>\n      <th>FWHM</th>\n      <th>Channel</th>\n      <th>Left</th>\n      <th>PW</th>\n      <th>Cts/Sec</th>\n      <th>...</th>\n      <th>Energy Calibration Used Done On</th>\n      <th>Efficiency Calibration Used Done On</th>\n      <th>Efficiency ID</th>\n      <th>Peak Analysis Report                    10.12.2020  8</th>\n      <th>Peak Analysis Performed on</th>\n      <th>Peak Analysis From Channel</th>\n      <th>Peak Search Sensitivity</th>\n      <th>Max Iterations</th>\n      <th>Use Fixed FWHM</th>\n      <th>Peak Fit Engine Name</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows Ã— 37 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 395
    }
   ],
   "source": [
    "df[df[\"Max Iterations\"].apply(lambda x: x.isnumeric())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'float'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-396-fe28c4975667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;36m0.134\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;36m0.286\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m~\u001b[0m\u001b[0;36m0.00046\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;36m0.52115\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"2.65*\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary ~: 'float'"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    0.134, \n",
    "    0.286, \n",
    "    ~0.00046,\n",
    "    0.52115, \n",
    "    \"2.65*\",\n",
    "    493, \n",
    "    \"3*\"\n",
    "]\n",
    "for num in test:\n",
    "    print(re.findall(r\"[\\d\\.\\d]+\", str(num))[0])\n",
    "\n",
    "    #z = re.match(r\"[\\.\\d]\", str(num))\n",
    "    #if z:\n",
    "    #    print(z.groups())\n",
    "    #else:\n",
    "    #    print(\"No match\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"downloads/searchE150.05pm1.05tMin120tMax100000.0.html\"\n",
    "html_file = open(path, \"r\")\n",
    "soup = BeautifulSoup(html_file.read(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = gammas[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-4b666c1c4e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"td\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "energy = row.find_all(\"td\")[5]\n",
    "print(energy.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['149.0', '3']"
      ]
     },
     "metadata": {},
     "execution_count": 191
    }
   ],
   "source": [
    "energy.get_text().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "energy.find_all(\"i\")[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pd.read_csv(\"out/M1-C1-Udepl-120.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "758         0.01\n",
       "459         0.01\n",
       "330         0.01\n",
       "297         0.01\n",
       "757         0.01\n",
       "          ...   \n",
       "1221    10000.10\n",
       "1253    10000.10\n",
       "110     10000.10\n",
       "1389    10000.10\n",
       "0       10000.10\n",
       "Name: Ig, Length: 2290, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 352
    }
   ],
   "source": [
    "ll[\"Ig\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('downloads/scratch.html', <http.client.HTTPMessage at 0x7f6238e92250>)"
      ]
     },
     "metadata": {},
     "execution_count": 412
    }
   ],
   "source": [
    "url = \"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=630150\"\n",
    "path = \"downloads/scratch.html\"\n",
    "urllib.request.urlretrieve(url, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = open(path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap = BeautifulSoup(html_file.read(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Charged\\xa0particle reactionFast\\xa0neutron activation'"
      ]
     },
     "metadata": {},
     "execution_count": 456
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['198', 'm', 'Tl']\n['155', '', 'Ho']\n['135', '', 'I']\n['85', 'm2', 'Y']\n['85', 'm', 'Y']\n['135', '', 'Sm']\n['135', 'm', 'Sm']\n"
     ]
    }
   ],
   "source": [
    "sett = [\"198mTl\", \"155Ho\", \"135I\", \"85m2Y\", \"85mY\", \"135Sm\", \"135mSm\"]\n",
    "for isotope in sett:\n",
    "    print(re.split(r'(\\d{2,3})(m{0,1}\\d{0,1})(\\w+)', isotope)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}