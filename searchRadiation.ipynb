{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "590f3899dd7b9bcfd4cbc68d67e174e21f00fe45394f2e3932fd522000967c3f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import numba\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "\n",
    "from getIg import getZ\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_get_text(cell):\n",
    "    return cell.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@numba.jit\n",
    "def process_radiation_search(download_path):\n",
    "    html_file = open(download_path, \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    table = soup.find_all(\"table\")[0]\n",
    "    gammas = table.find_all(\"tr\")\n",
    "    init_dict = {\"E_tab\": [0], \"Ig\": [0], \"Decay_Mode\": [\"b-\"], \"half_life\": [\"3 m\"], \"Isotope\": [\"Tu\"]}\n",
    "    gamma_df = pd.DataFrame(init_dict)\n",
    "\n",
    "    for gamma_row in gammas[2:-2]:\n",
    "        vals = list(map(func_get_text, gamma_row.find_all(\"td\")))\n",
    "        try:\n",
    "            gamma_df = gamma_df.append({\"E_tab\": vals[0].split()[0], \"Ig\": vals[1].split()[0], \"Decay_Mode\": vals[2], \"half_life\": vals[3], \"Isotope\": vals[4]}, ignore_index=True)\n",
    "        except:\n",
    "            print(\"******* MISSING INTENSITY **************\")\n",
    "            #print(vals)\n",
    "            continue\n",
    "    return gamma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gammas(energy, fwhm, t_min, t_max):\n",
    "    print(energy)\n",
    "    e_min = energy - fwhm\n",
    "    e_max = energy + fwhm\n",
    "    output_file = f\"downloads/searchE{energy}pm{fwhm}tMin{t_min}tMax{t_max}.html\"\n",
    "    if not os.path.isfile(output_file):\n",
    "        request_url = f\"http://nucleardata.nuclear.lu.se/toi/Gamma.asp?sql=&Min={e_min}&Max={e_max}&HlifeMin={t_min}&tMinStr={t_min}+s&HlifeMax={t_max}&tMaxStr={t_max}+s\"\n",
    "        urllib.request.urlretrieve(request_url, output_file)\n",
    "        print(f\"File {output_file} downloaded.\")\n",
    "    \n",
    "    gamma_df = process_radiation_search(output_file)\n",
    "    gamma_df[\"Energy\"] = energy\n",
    "    gamma_df[\"FWHM\"] = fwhm\n",
    "    gamma_df[\"half_life_searched\"] = f\"{t_min} - {t_max}\"\n",
    "    gamma_df = gamma_df.drop([0])\n",
    "    return gamma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_star(some_string):\n",
    "    if \"*\" in str(some_string) or \"~\" in str(some_string) or \"<\" in str(some_string) or \">\" in str(some_string):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_gammas(df, t_min, t_max, e_thr):\n",
    "    df[\"Ig\"] = int(1000.1)\n",
    "    for row in df.iterrows():\n",
    "        possible_gammas = find_gammas(row[1][\"Energy\"], row[1][\"FWHM\"], t_min, t_max)\n",
    "        df = df.append(possible_gammas, ignore_index=True)\n",
    "    #print(f\"DF size is {df.shape}\")\n",
    "    drop_columns = [\n",
    "        \"Fit\", \"Filename\", \"Sample Identification\", \n",
    "        \"Sample Type\", \"Sample Geometry\", \n",
    "        \"Sample Size\", \"Efficiency ID\", \n",
    "        \"Peak Analysis Report                    2.12.2020  10\"\n",
    "        ]\n",
    "    drop_columns3 = [\"Peak Analysis From Channel\", \"Peak Search Sensitivity\", \"Max Iterations\"]\n",
    "    drop_columns4 = [\"Use Fixed FWHM\", \"Peak Fit Engine Name\"]\n",
    "    df = df.drop(columns=drop_columns)\n",
    "    #df = df.drop(columns=drop_columns2)\n",
    "    df = df.drop(columns=drop_columns3)\n",
    "    df = df.drop(columns=drop_columns4)\n",
    "    print(df.columns)\n",
    "\n",
    "    # change columns order\n",
    "    old_column_order = df.columns.tolist()\n",
    "    first_cols = [\"Energy\", \"FWHM\", \"E_tab\", \"Area\", \"%err\", \"Ig\", \"half_life\", \"Isotope\", \"Real Time\", \"Live Time\"]\n",
    "    new_cols = first_cols + list(set(old_column_order) - set(first_cols))\n",
    "    df = df[new_cols]\n",
    "    df[\"Real Time\"] = df[\"Real Time\"].apply(lambda x: float(str(x).split(' ')[0]))\n",
    "    df[\"Live Time\"] = df[\"Live Time\"].apply(lambda x: float(str(x).split(' ')[0]))\n",
    "    #df = df[df[\"Ig\"].apply(lambda x: str(x).isnumeric())]\n",
    "    #df[\"Ig\"] = pd.to_numeric(df['Ig'], errors='coerce')\n",
    "\n",
    "    \n",
    "    df = df[df[\"Ig\"] != \"*\"]\n",
    "    df = df[df[\"Ig\"] != \"\"]\n",
    "\n",
    "    df[\"Has_star\"] = df[\"Ig\"].apply(has_star)\n",
    "    df = df[df[\"Has_star\"] == 0]\n",
    "\n",
    "    #df[\"Ig\"] = df[\"Ig\"].apply(float(re.findall(r\"[\\d\\.\\d]+\", str(x))[0]))\n",
    "\n",
    "    df['Ig'] = df['Ig'].astype(float)\n",
    "    df = df[df[\"Ig\"] >= e_thr]\n",
    "\n",
    "    df = df.sort_values(by=[\"Energy\", \"Ig\"], ascending=[True, False])\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_origin(df, origins_dict):\n",
    "    df[\"Origin\"] = \"not set\"\n",
    "    #for row in df.iterrows():\n",
    "    for i in range(df.shape[0]):\n",
    "        print(df[\"Isotope\"].loc[i])\n",
    "        df[\"Origin\"].loc[i], origins_dict = find_origin(df[\"Isotope\"].loc[i], origins_dict)\n",
    "\n",
    "    return df, origin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_origin(isotope, origin_dict):\n",
    "    #try:\n",
    "    if origin_dict.get(isotope) != None:\n",
    "        print(\"Found\")\n",
    "        print(origin_dict.get(isotope))\n",
    "        return origin_dict.get(isotope), origin_dict\n",
    "    else:\n",
    "        print(\"Not found\")\n",
    "        return add_isotope_origin(isotope, origin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_isotope_origin(isotope, origin_dict):\n",
    "    print(f\"isotope is {isotope}, length is {len(str(isotope))}\")\n",
    "    if str(isotope) == \"nan\":\n",
    "        print(\"it is nana\")\n",
    "        return None, origin_dict\n",
    "    else:\n",
    "        print(f\"Isotope is {isotope}\")\n",
    "        A, metastable, element = re.split(r'(\\d{2,3})(m{0,1}\\d{0,1})(\\w+)', isotope)[1:-1]\n",
    "\n",
    "        if metastable == \"m\":\n",
    "            A += 300\n",
    "        elif metastable == \"m2\":\n",
    "            A += 600\n",
    "        print(list(element))\n",
    "        url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={getZ(element)}0{A}\"\n",
    "        download_path = \"downloads/temp.html\"\n",
    "        urllib.request.urlretrieve(url, download_path)\n",
    "        html_file = open(download_path, \"r\")\n",
    "        table = BeautifulSoap(html_file.read(), 'lxml').find_all(\"table\")[1]\n",
    "        try:\n",
    "            origin_dict[isotope] = table.find_all(\"tr\")[7].find(\"td\").get_text(strip=True)\n",
    "        except:\n",
    "            origin_dict[isotope] = \"???\"\n",
    "        \n",
    "        return origin_dict.get(isotope), origin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"parsed_reports/M1-C1-Udepl-120.csv\", index_col=0)\n",
    "#all_gammas = add_all_gammas(df, 120, 1e5, 1e-2)\n",
    "\n",
    "#all_gammas.to_csv(\"out/M1-C1-Udepl-120.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"aux_data/origins.json\", \"w\") as outfile:  \n",
    "    json.dump(origins, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"out/M1-C1-Udepl-120_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file \n",
    "with open('aux_data/origins.json', \"r\") as origin_file: \n",
    "    origin_dict = json.load(origin_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'1H': 'Naturally occurring'}\nnan\nNot found\nisotope is nan, length is 3\nit is nana\n120Xe\nNot found\nisotope is 120Xe, length is 5\nIsotope is 120Xe\n['X', 'e']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Xe'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-387-1fa7cc2e97bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-380-6e30e1d9bf0b>\u001b[0m in \u001b[0;36madd_origin\u001b[0;34m(df, origins_dict)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Isotope\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Origin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigins_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Isotope\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigins_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-381-41726efdb769>\u001b[0m in \u001b[0;36mfind_origin\u001b[0;34m(isotope, origin_dict)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0madd_isotope_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misotope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-382-cc00d48a483b>\u001b[0m in \u001b[0;36madd_isotope_origin\u001b[0;34m(isotope, origin_dict)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={getZ(element)}0{A}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdownload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"downloads/temp.html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HPGeResAnalyzer/getIg.py\u001b[0m in \u001b[0;36mgetZ\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"U\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m\"Pu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m94\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     }\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0melement_Z\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Xe'"
     ]
    }
   ],
   "source": [
    "print(origin_dict)\n",
    "df, origins = add_origin(df, origin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"aux_data/origins2.json\", \"w\") as outfile:  \n",
    "    json.dump(origins, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"out/scratch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "105    None\n",
       "106    None\n",
       "107    None\n",
       "108    None\n",
       "109    None\n",
       "Name: Origin, Length: 110, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "df[\"Origin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('downloads/scratch.html', <http.client.HTTPMessage at 0x7f3f913636a0>)"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "url = \"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=630150\"\n",
    "path = \"downloads/scratch.html\"\n",
    "urllib.request.urlretrieve(url, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = open(path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap = BeautifulSoup(html_file.read(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['198', 'm', 'Tl']\n['155', '', 'Ho']\n['135', '', 'I']\n['85', 'm2', 'Y']\n['85', 'm', 'Y']\n['135', '', 'Sm']\n['135', 'm', 'Sm']\n"
     ]
    }
   ],
   "source": [
    "sett = [\"198mTl\", \"155Ho\", \"135I\", \"85m2Y\", \"85mY\", \"135Sm\", \"135mSm\"]\n",
    "for isotope in sett:\n",
    "    print(re.split(r'(\\d{2,3})(m{0,1}\\d{0,1})(\\w+)', isotope)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "metadata": {},
     "execution_count": 390
    }
   ],
   "source": [
    "getZ(\"\")"
   ]
  }
 ]
}