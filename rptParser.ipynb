{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import dateutil.parser as dparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_header(lines):\n",
    "    header = {}\n",
    "    datetime_columns = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.isspace():\n",
    "            if \":\" in line:\n",
    "                new_key, new_val = [x.strip() for x in line.split(':',maxsplit=1)]\n",
    "                if re.match(\"\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}[ \\d{1,2}\\:\\d{1,2}\\:\\d{1,2}]*\", new_val):\n",
    "                    new_val = dparser.parse(new_val, fuzzy=True)\n",
    "                    datetime_columns.append(new_key)\n",
    "\n",
    "                header[new_key] = new_val\n",
    "    \n",
    "    return header, datetime_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(lines):\n",
    "    # UGLY, could be one-liner, or?\n",
    "    head = lines[0].split()\n",
    "    params_no = len(head)\n",
    "\n",
    "    data = dict.fromkeys(head)\n",
    "\n",
    "    # UGLY, I believe there shoould be a way of doing it without for loop\n",
    "    for key in data:\n",
    "        data[key] = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        if not \"Bkgnd\" in line:\n",
    "            if len(line.split()) == params_no:\n",
    "                # UGLY, do it in one line\n",
    "                for i in range(params_no):\n",
    "                    data[head[i]].append(line.split()[i])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_RPT(rpt_file):\n",
    "    my_file = open(rpt_file, 'r')\n",
    "    lines = my_file.readlines()\n",
    "\n",
    "    lookup = \"Bkgnd\"\n",
    "    for line in lines:\n",
    "        if lookup in line:\n",
    "            split_num = lines.index(line)\n",
    "            break\n",
    "\n",
    "    header_lines = lines[0:split_num]\n",
    "    data_lines = lines[split_num:-1]\n",
    "\n",
    "    header, datetime_columns = parse_header(header_lines)\n",
    "    data = parse_data(data_lines)\n",
    "\n",
    "    meta_df = pd.DataFrame(header, index=[0])\n",
    "    rpt_df = pd.DataFrame(data)\n",
    "    \n",
    "    return meta_df, rpt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"raw_reports\"):\n",
    "    raise Exception(\"Folder 'raw_reports' not found. Consider creating it and moving RPT files there.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"./parsed_reports\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rpt_file in glob.iglob(\"./raw_reports/*.RPT\"):\n",
    "    meta_df, data_df = parse_RPT(rpt_file)\n",
    "\n",
    "    name = (rpt_file.split('.')[-2]).split('/')[-1]\n",
    "    meta_df.to_csv(f\"parsed_reports/meta_{name}.csv\")\n",
    "    rpt_df.to_csv(f\"parsed_reports/{name}.csv\")"
   ]
  }
 ]
}