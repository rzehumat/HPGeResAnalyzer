{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import dateutil.parser as dparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_header(lines):\n",
    "    header = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.isspace():\n",
    "            if \":\" in line:\n",
    "                new_key, new_val = [x.strip() for x in line.split(':',maxsplit=1)]\n",
    "                try:\n",
    "                    new_val = dparser.parse(new_val, fuzzy=True)\n",
    "                except:\n",
    "                    print(\"foo\")\n",
    "\n",
    "                header[new_key] = new_val\n",
    "    \n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(lines):\n",
    "    # UGLY, could be one-liner, or?\n",
    "    head = lines[0].split()\n",
    "    params_no = len(head)\n",
    "\n",
    "    data = dict.fromkeys(head)\n",
    "\n",
    "    # UGLY, I believe there shoould be a way of doing it without for loop\n",
    "    for key in data:\n",
    "        data[key] = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        if not \"Bkgnd\" in line:\n",
    "            if len(line.split()) == params_no:\n",
    "                # UGLY, do it in one line\n",
    "                for i in range(params_no):\n",
    "                    data[head[i]].append(line.split()[i])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_RPT(rpt_file):\n",
    "    my_file = open(rpt_file, 'r')\n",
    "    lines = my_file.readlines()\n",
    "\n",
    "    lookup = \"Bkgnd\"\n",
    "    for line in lines:\n",
    "        #print(\"line is\")\n",
    "        #print(line)\n",
    "        if lookup in line:\n",
    "            split_num = lines.index(line)\n",
    "            print(\"line to break in\")\n",
    "            print(line)\n",
    "            break\n",
    "\n",
    "    header_lines = lines[0:split_num]\n",
    "    data_lines = lines[split_num:-1]\n",
    "\n",
    "    header = parse_header(header_lines)\n",
    "    data = parse_data(data_lines)\n",
    "    \n",
    "    return header, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"raw_reports\"):\n",
    "    raise Exception(\"Folder 'raw_reports' not found. Consider creating it and moving RPT files there.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"./parsed_reports\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./raw_reports/M5-C1-Udepl-3.RPT\nline to break in\n   Pk IT  Energy      Area   Bkgnd  FWHM Channel  Left  PW  Cts/Sec  %err   Fit\n\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-310-db6dcda35c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmeta_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdatetime_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmeta_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatetime_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatetime_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mrpt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrpt_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/miFirstEnv/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assemble_from_unit_mappings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/miFirstEnv/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_assemble_from_unit_mappings\u001b[0;34m(arg, errors, tz)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0m_required\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    908\u001b[0m             \u001b[0;34m\"to assemble mappings requires at least that \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0;34mf\"[year, month, day] be specified: [{_required}] is missing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing"
     ]
    }
   ],
   "source": [
    "for rpt_file in glob.iglob(\"./raw_reports/*.RPT\"):\n",
    "    print(rpt_file)\n",
    "    header, data = parse_RPT(rpt_file)\n",
    "\n",
    "    meta_df = pd.DataFrame(header, index=[0])\n",
    "    datetime_columns = []\n",
    "    meta_df[datetime_columns] = pd.to_datetime(meta_df[datetime_columns])\n",
    "    rpt_df = pd.DataFrame(data)\n",
    "    name = (rpt_file.split('.')[-2]).split('/')[-1]\n",
    "    meta_df.to_csv(f\"parsed_reports/meta_{name}.csv\")\n",
    "    rpt_df.to_csv(f\"parsed_reports/{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1 entries, 0 to 0\nData columns (total 29 columns):\n #   Column                                                 Non-Null Count  Dtype \n---  ------                                                 --------------  ----- \n 0   Filename                                               1 non-null      object\n 1   Report Generated On                                    1 non-null      object\n 2   Sample Title                                           1 non-null      object\n 3   Sample Description                                     1 non-null      object\n 4   Sample Identification                                  1 non-null      object\n 5   Sample Type                                            1 non-null      object\n 6   Sample Geometry                                        1 non-null      object\n 7   Peak Locate Threshold                                  1 non-null      object\n 8   Peak Locate Range (in channels)                        1 non-null      object\n 9   Peak Area Range (in channels)                          1 non-null      object\n 10  Identification Energy Tolerance                        1 non-null      object\n 11  Sample Size                                            1 non-null      object\n 12  Sample Taken On                                        1 non-null      object\n 13  Acquisition Started                                    1 non-null      object\n 14  Live Time                                              1 non-null      object\n 15  Real Time                                              1 non-null      object\n 16  Dead Time                                              1 non-null      object\n 17  Energy Calibration Used Done On                        1 non-null      object\n 18  Efficiency Calibration Used Done On                    1 non-null      object\n 19  Efficiency ID                                          1 non-null      object\n 20  Peak Analysis Report                    24.11.2020 10  1 non-null      object\n 21  Configuration Title                                    1 non-null      object\n 22  Spectrum Title                                         1 non-null      object\n 23  Peak Analysis Performed on                             1 non-null      object\n 24  Peak Analysis From Channel                             1 non-null      object\n 25  Peak Search Sensitivity                                1 non-null      object\n 26  Max Iterations                                         1 non-null      object\n 27  Use Fixed FWHM                                         1 non-null      object\n 28  Peak Fit Engine Name                                   1 non-null      object\ndtypes: object(29)\nmemory usage: 240.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "meta_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./raw_reports/1M-28-30.RPT'"
      ]
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "rpt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    24.11.2020 10\n",
       "Name: Report Generated On, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "meta_df[\"Report Generated On\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"   ofslkslk   :            nvkslknsvlksvnjlkjn              \"\n",
    "new_key, new_val = [x.strip() for x in line.split(':',maxsplit=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'nvkslknsvlksvnjlkjn'"
      ]
     },
     "metadata": {},
     "execution_count": 287
    }
   ],
   "source": [
    "new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['aa', 'bb']\n"
     ]
    }
   ],
   "source": [
    "y = [x.strip() for x in [\"  aa  \", \" bb         \"]]\n",
    "print(y)"
   ]
  }
 ]
}