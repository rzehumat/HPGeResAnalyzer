{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "590f3899dd7b9bcfd4cbc68d67e174e21f00fe45394f2e3932fd522000967c3f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import decimal\n",
    "\n",
    "from math import pow\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_MIN = 1\n",
    "Z_MAX = 5\n",
    "TIME_CONVERSION = {\n",
    "    \"s\": 1, \n",
    "    \"m\": 60, \n",
    "    \"h\": 3600, \n",
    "    \"d\": 86400, \n",
    "    \"y\": 31556952\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_isotopes_list(Z):\n",
    "    request_url = f\"http://nucleardata.nuclear.lu.se/toi/listnuc.asp?sql=&Z={Z}\"\n",
    "    urllib.request.urlretrieve(request_url, f\"downloads/find_isotopes/z_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        download_isotopes_list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_one(Z):\n",
    "    html_path = f\"downloads/find_isotopes/z_{Z}.html\"\n",
    "    isotopes_lst_html = open(html_path, \"r\")\n",
    "    bs = BeautifulSoup(isotopes_lst_html.read(), 'lxml')\n",
    "    table = bs.find_all(\"table\")[0]\n",
    "    nuclide_lst = table.find_all('th')[9:]\n",
    "    abbr = str(nuclide_lst[0].find('a')).split('</sup>')[1][:-4]\n",
    "    out_file_path = f\"downloads/find_isotopes_parsed/{Z}_{abbr}.txt\"\n",
    "    out_file = open(out_file_path, \"w\")\n",
    "    out_file.write(f\"{Z}\\n\")\n",
    "    out_file.write(f\"{abbr}\\n\")\n",
    "    for nuclide in nuclide_lst:\n",
    "        out_file.write(f\"{nuclide.find('sup').get_text()}\\n\")\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        parse_isotopes_one(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_isotopes(Z):\n",
    "    down_dir = \"downloads/find_isotopes_parsed\"\n",
    "    files_lst = os.listdir(down_dir)\n",
    "    file_name = [s for s in files_lst if str(Z) == s.split('_')[0]]\n",
    "    isotopes_lst_file = open(f\"{down_dir}/{file_name[0]}\", \"r\")\n",
    "    lines = isotopes_lst_file.readlines()\n",
    "    abbr = lines[1].strip()\n",
    "    A_lst = lines[2:]\n",
    "    for A in A_lst:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\"\n",
    "        urllib.request.urlretrieve(url, f\"downloads/isotopes_html/{A}_{abbr}_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_elements(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        download_all_isotopes(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Igamma(A, element, Z):\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "\n",
    "    try:\n",
    "        gammas_table = soup.find_all(\"table\")[4]\n",
    "        gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "    except:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        print(colored(f\"Seems like there are no gamma-lines known for isotope {A}{element}.\", 'yellow'))\n",
    "        print(colored(\"Check yellow pages for reference.\", 'yellow'))\n",
    "        print(colored(f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\", 'yellow'))\n",
    "        return 1\n",
    "    energy = []\n",
    "    sigm_energy = []\n",
    "    i = []\n",
    "    sigm_i = []\n",
    "\n",
    "    print(gammas_table.find(\"font\").get_text(strip=True))\n",
    "\n",
    "    if \"Betas\" in gammas_table.find(\"font\").get_text(strip=True):\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        print(colored(f\"Seems like there are no gamma-lines known for isotope {A}{element}.\", 'yellow'))\n",
    "        print(colored(\"Check yellow pages for reference.\", 'yellow'))\n",
    "        print(colored(f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\", 'yellow'))\n",
    "        return 1\n",
    "        \n",
    "\n",
    "    for row in gammas_rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        e_val = cells[0].get_text(strip=True)\n",
    "        i_val = cells[1].get_text(strip=True)\n",
    "        try:\n",
    "            ig_val = float(i_val[:-1])\n",
    "            sigm_ig_val = float(i_val[-1])\n",
    "        except:\n",
    "            ig_val = float('NaN')\n",
    "            sigm_ig_val = float('NaN')\n",
    "       \n",
    "        energy.append(float(e_val[:-1]))\n",
    "        sigm_energy.append(int(e_val[-1]))\n",
    "        i.append(ig_val)\n",
    "        \n",
    "        sigm_i.append(sigm_ig_val)\n",
    "\n",
    "\n",
    "    df_dict = {\n",
    "        \"E_tab\": energy,\n",
    "        \"sigm_E\": sigm_energy, \n",
    "        \"Ig\": i,\n",
    "        \"sigm_Ig\": sigm_i\n",
    "        }\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df_name = f'downloads/ig_db/{A}{element}.csv'\n",
    "    df.to_csv(df_name)\n",
    "   \n",
    "    print(f\"Ig extracted from file 'downloads/{A}{element}.html' into '{df_name}'.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_elements(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        extract_element(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_element(Z):\n",
    "    html_lst = os.listdir(\"downloads/isotopes_html\")\n",
    "    element_files = [f for f in html_lst if str(Z) == f.split('_')[-1].split('.')[0]]\n",
    "    for isotope_file in element_files:\n",
    "        A, element, Z = (isotope_file.split('.')[0]).split('_')\n",
    "        print(f\"Extracting {A}{element}\")\n",
    "        extract_Igamma(A, element, Z)\n",
    "        extract_info(A, element, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(A, element, Z):\n",
    "    print(\"Extract info\")\n",
    "    print(A)\n",
    "    print(element)\n",
    "    print(Z)\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    table = soup.find_all(\"table\")[0]\n",
    "\n",
    "    info_rows = table.find_all(\"tr\")[6:16]\n",
    "    info_df = {}\n",
    "    #info_df = dict.fromkeys([\"Prod. mode:\", \"Half life:\"])\n",
    "    for row in info_rows:\n",
    "        #print(row)\n",
    "        key = (row.find_all(\"th\")[0]).get_text(strip=True)\n",
    "        try:\n",
    "            val = row.find_all(\"td\")[0]\n",
    "        except:\n",
    "            continue\n",
    "        if val.find(\"i\"):\n",
    "            sigm = val.find(\"i\").get_text(strip=True)\n",
    "            val = str(val.get_text(strip=True))[:-len(sigm)]\n",
    "            info_df[f\"sigm_{key}\"] = sigm\n",
    "        else:\n",
    "            val = val.get_text(strip=True)\n",
    "\n",
    "        info_df[key] = val\n",
    "    \n",
    "    info_df.pop('', None)\n",
    "    info_df = pd.DataFrame(info_df, index=[0])\n",
    "\n",
    "    columns = info_df.columns.tolist()\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i][:-1]\n",
    "        columns[i] = (columns[i]).replace(u'\\xa0', u' ')\n",
    "\n",
    "    info_df.columns = columns\n",
    "    info_df[\"Literature cut-off date\"] = pd.to_datetime(info_df[\"Literature cut-off date\"])\n",
    "\n",
    "    print(columns)\n",
    "\n",
    "    if \"Prod. mode\" in columns:\n",
    "        for mode in re.findall('[A-Z][^A-Z]*', str(info_df[\"Prod. mode\"][0])):\n",
    "            mode = mode.replace(u'\\xa0', u' ')\n",
    "            info_df[f\"Prod_mode_{mode}\"] = True\n",
    "    \n",
    "    for var in [\"Sn(keV)\", \"Sp(keV)\"]:\n",
    "        if var in columns:\n",
    "            orig_num = info_df[var][0]\n",
    "            print(info_df[var][0])\n",
    "            if info_df[var][0] == \"\":\n",
    "                continue\n",
    "\n",
    "            info_df[var] = info_df[var].astype(float)\n",
    "\n",
    "            sigma = f\"sigm_{var}\"\n",
    "            if sigma in columns and info_df[sigma][0] != \"sy\":\n",
    "                g = decimal.Decimal(orig_num)\n",
    "                print(info_df[sigma])\n",
    "                info_df[sigma] = int(info_df[sigma]) * pow(10, g.as_tuple().exponent)\n",
    "\n",
    "    print(info_df[\"Half life\"][0])\n",
    "    if info_df[\"Half life\"][0] == \"stable\":\n",
    "        info_df[\"Stable\"] = True\n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\"], errors=\"ignore\")\n",
    "        #if \"sigm_Sp(keV)\" in columns:\n",
    "        #    info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")\n",
    "    elif info_df[\"Half life\"][0] == \"\":\n",
    "        info_df[\"Stable\"] = False\n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\"], errors=\"ignore\")\n",
    "        #if \"sigm_Sp(keV)\" in columns:\n",
    "        #    info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")\n",
    "\n",
    "    else:\n",
    "        info_df[\"Stable\"] = False\n",
    "        hl_val, hl_unit = info_df[\"Half life\"][0].split()\n",
    "\n",
    "        if not hl_unit in list(TIME_CONVERSION.keys()):\n",
    "            info_df[\"Half-life [s]\"] = None\n",
    "        else:\n",
    "            d = decimal.Decimal(hl_val)\n",
    "            hl_val = float(hl_val)\n",
    "\n",
    "            info_df[\"Half-life [s]\"] = hl_val * TIME_CONVERSION[hl_unit]\n",
    "            if \"sigm_Half life\" in columns:\n",
    "                info_df[\"sigm_Half-life [s]\"] = int(info_df[\"sigm_Half life\"][0]) * pow(10, d.as_tuple().exponent) * TIME_CONVERSION[hl_unit]\n",
    "        \n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\"], errors=\"ignore\")\n",
    "        if \"sigm_Half life\" in columns:\n",
    "            info_df = info_df.drop(columns=[\"sigm_Half life\"])\n",
    "        if \"sigm_Sp(keV)\" in columns:\n",
    "            info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extract info\n6\nBe\n4\n['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n2.8E4\n593\n0    50\nName: sigm_Sp(keV), dtype: object\n92 keV\n"
     ]
    }
   ],
   "source": [
    "extract_info(6, \"Be\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Jp sigm_Sn(keV)  Sn(keV)  Sp(keV)    ENSDF citation  \\\n",
       "0  0+           sy  28000.0    593.0  NP A490,1 (1988)   \n",
       "\n",
       "  Literature cut-off date            Author(s)      References since cut-off  \\\n",
       "0              1988-06-01  F. Ajzenberg-Selove  6Be decay from 1988-98 (NSR)   \n",
       "\n",
       "   Stable  Half-life [s]  \n",
       "0   False            NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Jp</th>\n      <th>sigm_Sn(keV)</th>\n      <th>Sn(keV)</th>\n      <th>Sp(keV)</th>\n      <th>ENSDF citation</th>\n      <th>Literature cut-off date</th>\n      <th>Author(s)</th>\n      <th>References since cut-off</th>\n      <th>Stable</th>\n      <th>Half-life [s]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0+</td>\n      <td>sy</td>\n      <td>28000.0</td>\n      <td>593.0</td>\n      <td>NP A490,1 (1988)</td>\n      <td>1988-06-01</td>\n      <td>F. Ajzenberg-Selove</td>\n      <td>6Be decay from 1988-98 (NSR)</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 319
    }
   ],
   "source": [
    "aa = pd.read_csv(\"downloads/ig_db/info_6Be.csv\", index_col=0)\n",
    "aa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting 4H\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 4H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10004\u001b[0m\n",
      "Extract info\n",
      "4\n",
      "H\n",
      "1\n",
      "['Half life', 'Jp', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "Extracting 3H\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 3H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10003\u001b[0m\n",
      "Extract info\n",
      "3\n",
      "H\n",
      "1\n",
      "['sigm_Half life', 'Half life', 'Jp', 'Sn(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "6257.25\n",
      "12.33 y\n",
      "Extracting 6H\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 6H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10006\u001b[0m\n",
      "Extract info\n",
      "6\n",
      "H\n",
      "1\n",
      "['Half life', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "3.04E3\n",
      "0    10\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "\n",
      "Extracting 1H\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 1H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10001\u001b[0m\n",
      "Extract info\n",
      "1\n",
      "H\n",
      "1\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Prod. mode', 'Literature cut-off date', 'Author(s)', 'Update', 'References since cut-off']\n",
      "stable\n",
      "Extracting 2H\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 2H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10002\u001b[0m\n",
      "Extract info\n",
      "2\n",
      "H\n",
      "1\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Sn(keV)', 'Sp(keV)', 'Prod. mode', 'Literature cut-off date', 'Author(s)', 'Update']\n",
      "2224.57\n",
      "2224.57\n",
      "stable\n",
      "Extracting 5H\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 5H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10005\u001b[0m\n",
      "Extract info\n",
      "5\n",
      "H\n",
      "1\n",
      "['Half life', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "Extracting 10He\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 10He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20010\u001b[0m\n",
      "Extract info\n",
      "10\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'Literature cut-off date', 'Author(s)', 'Update', 'References since cut-off']\n",
      "8\n",
      "0    9\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "0.3 MeV\n",
      "Extracting 4He\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 4He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20004\u001b[0m\n",
      "Extract info\n",
      "4\n",
      "He\n",
      "2\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Sn(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)']\n",
      "20577.62\n",
      "19813.85\n",
      "stable\n",
      "Extracting 8He\n",
      "Gammas from8He (119.0 ms15)\n",
      "Ig extracted from file 'downloads/8He.html' into 'downloads/ig_db/8He.csv'.\n",
      "Extract info\n",
      "8\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2584\n",
      "0    31\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "119.0 ms\n",
      "Extracting 9He\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 9He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20009\u001b[0m\n",
      "Extract info\n",
      "9\n",
      "He\n",
      "2\n",
      "['Half life', 'Jp', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "0.30 MeV\n",
      "Extracting 5He\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 5He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20005\u001b[0m\n",
      "Extract info\n",
      "5\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2.183E4\n",
      "0    12\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "0.60 MeV\n",
      "Extracting 3He\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 3He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20003\u001b[0m\n",
      "Extract info\n",
      "3\n",
      "He\n",
      "2\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "5493.49\n",
      "stable\n",
      "Extracting 7He\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 7He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20007\u001b[0m\n",
      "Extract info\n",
      "7\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2.30E4\n",
      "0    3\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "160 keV\n",
      "Extracting 6He\n",
      "Betas from6He (806.7 ms15)\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 6He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20006\u001b[0m\n",
      "Extract info\n",
      "6\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "1863\n",
      "0    50\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "2.65E4\n",
      "0    9\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "806.7 ms\n",
      "Extracting 12Li\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 12Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30012\u001b[0m\n",
      "Extract info\n",
      "12\n",
      "Li\n",
      "3\n",
      "['Half life', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "\n",
      "Extracting 4Li\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 4Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30004\u001b[0m\n",
      "Extract info\n",
      "4\n",
      "Li\n",
      "3\n",
      "['Half life', 'Jp', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "Extracting 7Li\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 7Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30007\u001b[0m\n",
      "Extract info\n",
      "7\n",
      "Li\n",
      "3\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)']\n",
      "7249.96\n",
      "0    9\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "9975.4\n",
      "0    9\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "stable\n",
      "Extracting 6Li\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 6Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30006\u001b[0m\n",
      "Extract info\n",
      "6\n",
      "Li\n",
      "3\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)']\n",
      "5664\n",
      "0    50\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "4589\n",
      "0    50\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "stable\n",
      "Extracting 9Li\n",
      "Betas from9Li (178.3 ms4)\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 9Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30009\u001b[0m\n",
      "Extract info\n",
      "9\n",
      "Li\n",
      "3\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "4063.6\n",
      "0    20\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "13933\n",
      "0    7\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "178.3 ms\n",
      "Extracting 5Li\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 5Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30005\u001b[0m\n",
      "Extract info\n",
      "5\n",
      "Li\n",
      "3\n",
      "['Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2.171E4\n",
      "0    22\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "~1.5 MeV\n",
      "Extracting 11Li\n",
      "Gammas from11Li (8.5 ms2)\n",
      "Ig extracted from file 'downloads/11Li.html' into 'downloads/ig_db/11Li.csv'.\n",
      "Extract info\n",
      "11\n",
      "Li\n",
      "3\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "326\n",
      "0    31\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "15303\n",
      "0    75\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "8.5 ms\n",
      "Extracting 10Li\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 10Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30010\u001b[0m\n",
      "Extract info\n",
      "10\n",
      "Li\n",
      "3\n",
      "['sigm_Half life', 'Half life', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "15057\n",
      "0    64\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "1.2 MeV\n",
      "Extracting 8Li\n",
      "Betas from8Li (838 ms6)\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 8Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30008\u001b[0m\n",
      "Extract info\n",
      "8\n",
      "Li\n",
      "3\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2032.80\n",
      "0    12\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "12453\n",
      "0    30\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "838 ms\n",
      "Extracting 5Be\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 5Be.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40005\u001b[0m\n",
      "Extract info\n",
      "5\n",
      "Be\n",
      "4\n",
      "['Half life', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "\n",
      "Extracting 14Be\n",
      "Betas from14Be (4.35 ms17)\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 14Be.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40014\u001b[0m\n",
      "Extract info\n",
      "14\n",
      "Be\n",
      "4\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "1.8E3\n",
      "0    5\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "4.35 ms\n",
      "Extracting 8Be\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 8Be.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40008\u001b[0m\n",
      "Extract info\n",
      "8\n",
      "Be\n",
      "4\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "18899.2\n",
      "0    5\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "17255.0\n",
      "0    5\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "6.8 eV\n",
      "Extracting 7Be\n",
      "Gammas from7Be (53.12 d7)\n",
      "Ig extracted from file 'downloads/7Be.html' into 'downloads/ig_db/7Be.csv'.\n",
      "Extract info\n",
      "7\n",
      "Be\n",
      "4\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "10676\n",
      "0    5\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "5605.79\n",
      "0    9\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "53.12 d\n",
      "Extracting 12Be\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 12Be.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40012\u001b[0m\n",
      "Extract info\n",
      "12\n",
      "Be\n",
      "4\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "3169\n",
      "0    16\n",
      "Name: sigm_Sn(keV), dtype: object\n",
      "23008\n",
      "0    31\n",
      "Name: sigm_Sp(keV), dtype: object\n",
      "23.6 ms\n",
      "Extracting 6Be\n",
      "\u001b[33mSeems like there are no gamma-lines known for isotope 6Be.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40006\u001b[0m\n",
      "Extract info\n",
      "6\n",
      "Be\n",
      "4\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2.8E4\n",
      "0    sy\n",
      "Name: sigm_Sn(keV), dtype: object\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'sy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-314-3b1e694129a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparse_isotopes_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_MIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_MAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdownload_all_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_MAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mextract_all_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_MAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-311-1fec518517af>\u001b[0m in \u001b[0;36mextract_all_elements\u001b[0;34m(z_min, z_max)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_all_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_max\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mextract_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-312-6ce388b19c02>\u001b[0m in \u001b[0;36mextract_element\u001b[0;34m(Z)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting {A}{element}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mextract_Igamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mextract_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-313-90855268ed37>\u001b[0m in \u001b[0;36mextract_info\u001b[0;34m(A, element, Z)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0minfo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Half life\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot convert the series to {converter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'sy'"
     ]
    }
   ],
   "source": [
    "download_range(Z_MIN, Z_MAX)\n",
    "parse_isotopes_range(Z_MIN,Z_MAX)\n",
    "download_all_elements(Z_MIN, Z_MAX)\n",
    "extract_all_elements(Z_MIN, Z_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gammas from13B (17.36 ms16)\nIg extracted from file 'downloads/13B.html' into 'downloads/ig_db/13B.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    A = 13\n",
    "    element=\"B\"\n",
    "    Z = 5\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "\n",
    "    try:\n",
    "        gammas_table = soup.find_all(\"table\")[4]\n",
    "        gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "    except:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        print(colored(f\"Seems like there are no gamma-lines known for isotope {A}{element}.\", 'red'))\n",
    "        print(colored(\"Check yellow pages for reference.\", 'yellow'))\n",
    "        print(colored(f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\", 'yellow'))\n",
    "        #return 1\n",
    "    energy = []\n",
    "    sigm_energy = []\n",
    "    i = []\n",
    "    sigm_i = []\n",
    "\n",
    "    print(gammas_table.find(\"font\").get_text(strip=True))\n",
    "    for row in gammas_rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        e_val = cells[0].get_text(strip=True)\n",
    "        i_val = cells[1].get_text(strip=True)\n",
    "        try:\n",
    "            ig_val = float(i_val[:-1])\n",
    "            sigm_ig_val = float(i_val[-1])\n",
    "        except:\n",
    "            ig_val = float('NaN')\n",
    "            sigm_ig_val = float('NaN')\n",
    "       \n",
    "        \n",
    "        energy.append(float(e_val[:-1]))\n",
    "        sigm_energy.append(int(e_val[-1]))\n",
    "        i.append(ig_val)\n",
    "        \n",
    "        sigm_i.append(sigm_ig_val)\n",
    "\n",
    "\n",
    "    df_dict = {\n",
    "        \"E_tab\": energy,\n",
    "        \"sigm_E\": sigm_energy, \n",
    "        \"Ig\": i,\n",
    "        \"sigm_Ig\": sigm_i\n",
    "        }\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df_name = f'downloads/ig_db/{A}{element}.csv'\n",
    "    #df.to_csv(df_name)\n",
    "   \n",
    "    print(f\"Ig extracted from file 'downloads/{A}{element}.html' into '{df_name}'.\")\n",
    "    #return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    A = 9\n",
    "    element=\"Li\"\n",
    "    Z = 3\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "\n",
    "    gammas_table = soup.find_all(\"table\")[4]\n",
    "    gammas_rows = gammas_table.find_all('tr')[3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = gammas_table.find(\"font\").get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cype\n"
     ]
    }
   ],
   "source": [
    "if \"Betas\" in sss:\n",
    "    print(\"Cype\")"
   ]
  }
 ]
}