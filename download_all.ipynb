{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "590f3899dd7b9bcfd4cbc68d67e174e21f00fe45394f2e3932fd522000967c3f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import decimal\n",
    "\n",
    "from math import pow\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_MIN = 1\n",
    "Z_MAX = 112\n",
    "TIME_CONVERSION = {\n",
    "    \"s\": 1, \n",
    "    \"m\": 60, \n",
    "    \"h\": 3600, \n",
    "    \"d\": 86400, \n",
    "    \"y\": 31556952\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_isotopes_list(Z):\n",
    "    request_url = f\"http://nucleardata.nuclear.lu.se/toi/listnuc.asp?sql=&Z={Z}\"\n",
    "    urllib.request.urlretrieve(request_url, f\"downloads/find_isotopes/z_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        download_isotopes_list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_one(Z):\n",
    "    html_path = f\"downloads/find_isotopes/z_{Z}.html\"\n",
    "    isotopes_lst_html = open(html_path, \"r\")\n",
    "    bs = BeautifulSoup(isotopes_lst_html.read(), 'lxml')\n",
    "    table = bs.find_all(\"table\")[0]\n",
    "    nuclide_lst = table.find_all('th')[9:]\n",
    "    abbr = str(nuclide_lst[0].find('a')).split('</sup>')[1][:-4]\n",
    "    out_file_path = f\"downloads/find_isotopes_parsed/{Z}_{abbr}.txt\"\n",
    "    out_file = open(out_file_path, \"w\")\n",
    "    out_file.write(f\"{Z}\\n\")\n",
    "    out_file.write(f\"{abbr}\\n\")\n",
    "    for nuclide in nuclide_lst:\n",
    "        out_file.write(f\"{nuclide.find('sup').get_text()}\\n\")\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        parse_isotopes_one(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_isotopes(Z):\n",
    "    down_dir = \"downloads/find_isotopes_parsed\"\n",
    "    files_lst = os.listdir(down_dir)\n",
    "    file_name = [s for s in files_lst if str(Z) == s.split('_')[0]]\n",
    "    isotopes_lst_file = open(f\"{down_dir}/{file_name[0]}\", \"r\")\n",
    "    lines = isotopes_lst_file.readlines()\n",
    "    abbr = lines[1].strip()\n",
    "    A_lst = lines[2:]\n",
    "    for A in A_lst:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\"\n",
    "        urllib.request.urlretrieve(url, f\"downloads/isotopes_html/{A}_{abbr}_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_elements(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        download_all_isotopes(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Igamma(A, element, Z):\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "\n",
    "    try:\n",
    "        gammas_table = soup.find_all(\"table\")[4]\n",
    "        gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "    except:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        print(colored(f\"Seems like there are no gamma-lines known for isotope {A}{element}.\", 'red'))\n",
    "        print(colored(\"Check yellow pages for reference.\", 'yellow'))\n",
    "        print(colored(f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\", 'yellow'))\n",
    "        return 1\n",
    "    energy = []\n",
    "    sigm_energy = []\n",
    "    i = []\n",
    "    sigm_i = []\n",
    "\n",
    "    for row in gammas_rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        e_val = cells[0].get_text(strip=True)\n",
    "        i_val = cells[1].get_text(strip=True)\n",
    "        try:\n",
    "            ig_val = float(i_val[:-1])\n",
    "            sigm_ig_val = float(i_val[-1])\n",
    "        except:\n",
    "            ig_val = float('NaN')\n",
    "            sigm_ig_val = float('NaN')\n",
    "       \n",
    "        energy.append(float(e_val[:-1]))\n",
    "        sigm_energy.append(int(e_val[-1]))\n",
    "        i.append(ig_val)\n",
    "        \n",
    "        sigm_i.append(sigm_ig_val)\n",
    "\n",
    "\n",
    "    df_dict = {\n",
    "        \"E_tab\": energy,\n",
    "        \"sigm_E\": sigm_energy, \n",
    "        \"Ig\": i,\n",
    "        \"sigm_Ig\": sigm_i\n",
    "        }\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df_name = f'downloads/ig_db/{A}{element}.csv'\n",
    "    df.to_csv(df_name)\n",
    "   \n",
    "    print(f\"Ig extracted from file 'downloads/{A}{element}.html' into '{df_name}'.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_elements(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        extract_element(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_element(Z):\n",
    "    html_lst = os.listdir(\"downloads/isotopes_html\")\n",
    "    element_files = [f for f in html_lst if str(Z) == f.split('_')[-1].split('.')[0]]\n",
    "    for isotope_file in element_files:\n",
    "        A, element, Z = (isotope_file.split('.')[0]).split('_')\n",
    "        extract_Igamma(A, element, Z)\n",
    "        extract_info(A, element, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(A, element, Z):\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    table = soup.find_all(\"table\")[0]\n",
    "\n",
    "    info_rows = table.find_all(\"tr\")[6:16]\n",
    "    info_df = {}\n",
    "    for row in info_rows:\n",
    "        key = (row.find_all(\"th\")[0]).get_text(strip=True)\n",
    "        val = row.find_all(\"td\")[0]\n",
    "        if val.find(\"i\"):\n",
    "            sigm = val.find(\"i\").get_text(strip=True)\n",
    "            val = str(val.get_text(strip=True))[:-len(sigm)]\n",
    "            info_df[f\"sigm_{key}\"] = sigm\n",
    "        else:\n",
    "            val = val.get_text(strip=True)\n",
    "\n",
    "        info_df[key] = val\n",
    "    \n",
    "    info_df.pop('', None)\n",
    "    info_df = pd.DataFrame(info_df, index=[0])\n",
    "\n",
    "    columns = info_df.columns.tolist()\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i][:-1]\n",
    "        columns[i] = (columns[i]).replace(u'\\xa0', u' ')\n",
    "\n",
    "    info_df.columns = columns\n",
    "    info_df[\"Literature cut-off date\"] = pd.to_datetime(info_df[\"Literature cut-off date\"])\n",
    "\n",
    "    for mode in re.findall('[A-Z][^A-Z]*', str(info_df[\"Prod. mode\"][0])):\n",
    "        mode = mode.replace(u'\\xa0', u' ')\n",
    "        info_df[f\"Prod_mode_{mode}\"] = True\n",
    "    \n",
    "    g = decimal.Decimal(info_df[\"Sn(keV)\"][0])\n",
    "    info_df[\"Sn [keV]\"] = info_df[\"Sn(keV)\"].astype(float)\n",
    "    info_df[\"Sp [keV]\"] = info_df[\"Sp(keV)\"].astype(float)\n",
    "    \n",
    "    if \"sigm_Sp(keV)\" in columns:\n",
    "        info_df[\"sigm_Sp [keV]\"] = int(info_df[\"sigm_Sp(keV)\"]) * pow(10, g.as_tuple().exponent)\n",
    "\n",
    "    print(info_df[\"Half life\"][0])\n",
    "    if info_df[\"Half life\"][0] == \"stable\":\n",
    "        info_df[\"Stable\"] = True\n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\", \"Sn(keV)\", \"Sp(keV)\"])\n",
    "        if \"sigm_Sp(keV)\" in columns:\n",
    "            info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")\n",
    "    else:\n",
    "        info_df[\"Stable\"] = False\n",
    "        hl_val, hl_unit = info_df[\"Half life\"][0].split()\n",
    "        d = decimal.Decimal(hl_val)\n",
    "        hl_val = float(hl_val)\n",
    "        \n",
    "        info_df[\"Half-life [s]\"] = hl_val * TIME_CONVERSION[hl_unit]\n",
    "        if \"sigm_Half life\" in columns:\n",
    "            info_df[\"sigm_Half-life [s]\"] = int(info_df[\"sigm_Half life\"][0]) * pow(10, d.as_tuple().exponent) * TIME_CONVERSION[hl_unit]\n",
    "        \n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\",  \"Sn(keV)\", \"Sp(keV)\", \"sigm_Sp(keV)\"])\n",
    "        if \"sigm_Half life\" in columns:\n",
    "            info_df = info_df.drop(columns=[\"sigm_Half life\"])\n",
    "        if \"sigm_Sp(keV)\" in columns:\n",
    "            info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_range(Z_MIN, Z_MAX)\n",
    "parse_isotopes_range(Z_MIN,Z_MAX)\n",
    "download_all_elements(Z_MIN, Z_MAX)\n",
    "extract_all_elements(Z_MIN, Z_MAX)"
   ]
  }
 ]
}