{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "590f3899dd7b9bcfd4cbc68d67e174e21f00fe45394f2e3932fd522000967c3f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import decimal\n",
    "\n",
    "from math import pow\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_MIN = 1\n",
    "Z_MAX = 5\n",
    "TIME_CONVERSION = {\n",
    "    \"s\": 1, \n",
    "    \"m\": 60, \n",
    "    \"h\": 3600, \n",
    "    \"d\": 86400, \n",
    "    \"y\": 31556952\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_isotopes_list(Z):\n",
    "    request_url = f\"http://nucleardata.nuclear.lu.se/toi/listnuc.asp?sql=&Z={Z}\"\n",
    "    urllib.request.urlretrieve(request_url, f\"downloads/find_isotopes/z_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        download_isotopes_list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_one(Z):\n",
    "    html_path = f\"downloads/find_isotopes/z_{Z}.html\"\n",
    "    isotopes_lst_html = open(html_path, \"r\")\n",
    "    bs = BeautifulSoup(isotopes_lst_html.read(), 'lxml')\n",
    "    table = bs.find_all(\"table\")[0]\n",
    "    nuclide_lst = table.find_all('th')[9:]\n",
    "    abbr = str(nuclide_lst[0].find('a')).split('</sup>')[1][:-4]\n",
    "    out_file_path = f\"downloads/find_isotopes_parsed/{Z}_{abbr}.txt\"\n",
    "    out_file = open(out_file_path, \"w\")\n",
    "    out_file.write(f\"{Z}\\n\")\n",
    "    out_file.write(f\"{abbr}\\n\")\n",
    "    for nuclide in nuclide_lst:\n",
    "        out_file.write(f\"{nuclide.find('sup').get_text()}\\n\")\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        parse_isotopes_one(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_isotopes(Z):\n",
    "    down_dir = \"downloads/find_isotopes_parsed\"\n",
    "    files_lst = os.listdir(down_dir)\n",
    "    file_name = [s for s in files_lst if str(Z) == s.split('_')[0]]\n",
    "    isotopes_lst_file = open(f\"{down_dir}/{file_name[0]}\", \"r\")\n",
    "    lines = isotopes_lst_file.readlines()\n",
    "    abbr = lines[1].strip()\n",
    "    A_lst = lines[2:]\n",
    "    for A in A_lst:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\"\n",
    "        urllib.request.urlretrieve(url, f\"downloads/isotopes_html/{A}_{abbr}_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_elements(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        download_all_isotopes(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Igamma(A, element, Z):\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "\n",
    "    try:\n",
    "        gammas_table = soup.find_all(\"table\")[4]\n",
    "        gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "    except:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        print(colored(f\"Seems like there are no gamma-lines known for isotope {A}{element}.\", 'red'))\n",
    "        print(colored(\"Check yellow pages for reference.\", 'yellow'))\n",
    "        print(colored(f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\", 'yellow'))\n",
    "        return 1\n",
    "    energy = []\n",
    "    sigm_energy = []\n",
    "    i = []\n",
    "    sigm_i = []\n",
    "\n",
    "    for row in gammas_rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        e_val = cells[0].get_text(strip=True)\n",
    "        i_val = cells[1].get_text(strip=True)\n",
    "        try:\n",
    "            ig_val = float(i_val[:-1])\n",
    "            sigm_ig_val = float(i_val[-1])\n",
    "        except:\n",
    "            ig_val = float('NaN')\n",
    "            sigm_ig_val = float('NaN')\n",
    "       \n",
    "        energy.append(float(e_val[:-1]))\n",
    "        sigm_energy.append(int(e_val[-1]))\n",
    "        i.append(ig_val)\n",
    "        \n",
    "        sigm_i.append(sigm_ig_val)\n",
    "\n",
    "\n",
    "    df_dict = {\n",
    "        \"E_tab\": energy,\n",
    "        \"sigm_E\": sigm_energy, \n",
    "        \"Ig\": i,\n",
    "        \"sigm_Ig\": sigm_i\n",
    "        }\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df_name = f'downloads/ig_db/{A}{element}.csv'\n",
    "    df.to_csv(df_name)\n",
    "   \n",
    "    print(f\"Ig extracted from file 'downloads/{A}{element}.html' into '{df_name}'.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_elements(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        extract_element(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_element(Z):\n",
    "    html_lst = os.listdir(\"downloads/isotopes_html\")\n",
    "    element_files = [f for f in html_lst if str(Z) == f.split('_')[-1].split('.')[0]]\n",
    "    for isotope_file in element_files:\n",
    "        A, element, Z = (isotope_file.split('.')[0]).split('_')\n",
    "        print(f\"Extracting {A}{element}\")\n",
    "        extract_Igamma(A, element, Z)\n",
    "        extract_info(A, element, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(A, element, Z):\n",
    "    print(\"Extract info\")\n",
    "    print(A)\n",
    "    print(element)\n",
    "    print(Z)\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    table = soup.find_all(\"table\")[0]\n",
    "\n",
    "    info_rows = table.find_all(\"tr\")[6:16]\n",
    "    info_df = {}\n",
    "    #info_df = dict.fromkeys([\"Prod. mode:\", \"Half life:\"])\n",
    "    for row in info_rows:\n",
    "        #print(row)\n",
    "        key = (row.find_all(\"th\")[0]).get_text(strip=True)\n",
    "        try:\n",
    "            val = row.find_all(\"td\")[0]\n",
    "        except:\n",
    "            continue\n",
    "        if val.find(\"i\"):\n",
    "            sigm = val.find(\"i\").get_text(strip=True)\n",
    "            val = str(val.get_text(strip=True))[:-len(sigm)]\n",
    "            info_df[f\"sigm_{key}\"] = sigm\n",
    "        else:\n",
    "            val = val.get_text(strip=True)\n",
    "\n",
    "        info_df[key] = val\n",
    "    \n",
    "    info_df.pop('', None)\n",
    "    info_df = pd.DataFrame(info_df, index=[0])\n",
    "\n",
    "    columns = info_df.columns.tolist()\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i][:-1]\n",
    "        columns[i] = (columns[i]).replace(u'\\xa0', u' ')\n",
    "\n",
    "    info_df.columns = columns\n",
    "    info_df[\"Literature cut-off date\"] = pd.to_datetime(info_df[\"Literature cut-off date\"])\n",
    "\n",
    "    print(columns)\n",
    "\n",
    "    if \"Prod. mode\" in columns:\n",
    "        for mode in re.findall('[A-Z][^A-Z]*', str(info_df[\"Prod. mode\"][0])):\n",
    "            mode = mode.replace(u'\\xa0', u' ')\n",
    "            info_df[f\"Prod_mode_{mode}\"] = True\n",
    "    \n",
    "    for var in [\"Sn(keV)\", \"Sp(keV)\"]:\n",
    "        if var in columns:\n",
    "            orig_num = info_df[var][0]\n",
    "            print(info_df[var][0])\n",
    "            if info_df[var][0] == \"\":\n",
    "                continue\n",
    "\n",
    "            info_df[var] = info_df[var].astype(float)\n",
    "\n",
    "            sigma = f\"sigm_{var}\"\n",
    "            if sigma in columns:\n",
    "                g = decimal.Decimal(orig_num)\n",
    "                info_df[sigma] = int(info_df[sigma]) * pow(10, g.as_tuple().exponent)\n",
    "\n",
    "    print(info_df[\"Half life\"][0])\n",
    "    if info_df[\"Half life\"][0] == \"stable\":\n",
    "        info_df[\"Stable\"] = True\n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\"], errors=\"ignore\")\n",
    "        #if \"sigm_Sp(keV)\" in columns:\n",
    "        #    info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")\n",
    "    elif info_df[\"Half life\"][0] == \"\":\n",
    "        info_df[\"Stable\"] = False\n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\"], errors=\"ignore\")\n",
    "        #if \"sigm_Sp(keV)\" in columns:\n",
    "        #    info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")\n",
    "\n",
    "    else:\n",
    "        info_df[\"Stable\"] = False\n",
    "        hl_val, hl_unit = info_df[\"Half life\"][0].split()\n",
    "\n",
    "        if not hl_unit in list(TIME_CONVERSION.keys()):\n",
    "            info_df[\"Half-life [s]\"] = None\n",
    "        else:\n",
    "            d = decimal.Decimal(hl_val)\n",
    "            hl_val = float(hl_val)\n",
    "\n",
    "            info_df[\"Half-life [s]\"] = hl_val * TIME_CONVERSION[hl_unit]\n",
    "            if \"sigm_Half life\" in columns:\n",
    "                info_df[\"sigm_Half-life [s]\"] = int(info_df[\"sigm_Half life\"][0]) * pow(10, d.as_tuple().exponent) * TIME_CONVERSION[hl_unit]\n",
    "        \n",
    "        info_df = info_df.drop(columns=[\"Prod. mode\", \"Half life\"], errors=\"ignore\")\n",
    "        if \"sigm_Half life\" in columns:\n",
    "            info_df = info_df.drop(columns=[\"sigm_Half life\"])\n",
    "        if \"sigm_Sp(keV)\" in columns:\n",
    "            info_df = info_df.drop(columns=[\"sigm_Sp(keV)\"])\n",
    "        info_df.to_csv(f\"downloads/ig_db/info_{A}{element}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting 4H\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 4H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10004\u001b[0m\n",
      "Extract info\n",
      "4\n",
      "H\n",
      "1\n",
      "['Half life', 'Jp', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "Extracting 3H\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 3H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10003\u001b[0m\n",
      "Extract info\n",
      "3\n",
      "H\n",
      "1\n",
      "['sigm_Half life', 'Half life', 'Jp', 'Sn(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "6257.25\n",
      "12.33 y\n",
      "Extracting 6H\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 6H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10006\u001b[0m\n",
      "Extract info\n",
      "6\n",
      "H\n",
      "1\n",
      "['Half life', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "3.04E3\n",
      "\n",
      "Extracting 1H\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 1H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10001\u001b[0m\n",
      "Extract info\n",
      "1\n",
      "H\n",
      "1\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Prod. mode', 'Literature cut-off date', 'Author(s)', 'Update', 'References since cut-off']\n",
      "stable\n",
      "Extracting 2H\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 2H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10002\u001b[0m\n",
      "Extract info\n",
      "2\n",
      "H\n",
      "1\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Sn(keV)', 'Sp(keV)', 'Prod. mode', 'Literature cut-off date', 'Author(s)', 'Update']\n",
      "2224.57\n",
      "2224.57\n",
      "stable\n",
      "Extracting 5H\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 5H.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=10005\u001b[0m\n",
      "Extract info\n",
      "5\n",
      "H\n",
      "1\n",
      "['Half life', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "Extracting 10He\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 10He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20010\u001b[0m\n",
      "Extract info\n",
      "10\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'Literature cut-off date', 'Author(s)', 'Update', 'References since cut-off']\n",
      "8\n",
      "0.3 MeV\n",
      "Extracting 4He\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 4He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20004\u001b[0m\n",
      "Extract info\n",
      "4\n",
      "He\n",
      "2\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Sn(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)']\n",
      "20577.62\n",
      "19813.85\n",
      "stable\n",
      "Extracting 8He\n",
      "Ig extracted from file 'downloads/8He.html' into 'downloads/ig_db/8He.csv'.\n",
      "Extract info\n",
      "8\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2584\n",
      "119.0 ms\n",
      "Extracting 9He\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 9He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20009\u001b[0m\n",
      "Extract info\n",
      "9\n",
      "He\n",
      "2\n",
      "['Half life', 'Jp', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "0.30 MeV\n",
      "Extracting 5He\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 5He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20005\u001b[0m\n",
      "Extract info\n",
      "5\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2.183E4\n",
      "0.60 MeV\n",
      "Extracting 3He\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 3He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20003\u001b[0m\n",
      "Extract info\n",
      "3\n",
      "He\n",
      "2\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "5493.49\n",
      "stable\n",
      "Extracting 7He\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 7He.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=20007\u001b[0m\n",
      "Extract info\n",
      "7\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sp(keV)', 'Sp(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "2.30E4\n",
      "160 keV\n",
      "Extracting 6He\n",
      "Ig extracted from file 'downloads/6He.html' into 'downloads/ig_db/6He.csv'.\n",
      "Extract info\n",
      "6\n",
      "He\n",
      "2\n",
      "['sigm_Half life', 'Half life', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "1863\n",
      "2.65E4\n",
      "806.7 ms\n",
      "Extracting 12Li\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 12Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30012\u001b[0m\n",
      "Extract info\n",
      "12\n",
      "Li\n",
      "3\n",
      "['Half life', 'sigm_Sn(keV)', 'Sn(keV)', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "\n",
      "Extracting 4Li\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 4Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30004\u001b[0m\n",
      "Extract info\n",
      "4\n",
      "Li\n",
      "3\n",
      "['Half life', 'Jp', 'ENSDF citation', 'Literature cut-off date', 'Author(s)', 'References since cut-off']\n",
      "\n",
      "Extracting 7Li\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 7Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30007\u001b[0m\n",
      "Extract info\n",
      "7\n",
      "Li\n",
      "3\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)']\n",
      "7249.96\n",
      "9975.4\n",
      "stable\n",
      "Extracting 6Li\n",
      "\u001b[31mSeems like there are no gamma-lines known for isotope 6Li.\u001b[0m\n",
      "\u001b[33mCheck yellow pages for reference.\u001b[0m\n",
      "\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=30006\u001b[0m\n",
      "Extract info\n",
      "6\n",
      "Li\n",
      "3\n",
      "['Half life', 'sigm_Abundance', 'Abundance', 'Jp', 'sigm_Sn(keV)', 'Sn(keV)', 'sigm_Sp(keV)', 'Sp(keV)', 'Prod. mode', 'ENSDF citation', 'Literature cut-off date', 'Author(s)']\n",
      "5664\n",
      "4589\n",
      "stable\n",
      "Extracting 9Li\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1796,'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-3b1e694129a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparse_isotopes_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_MIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_MAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdownload_all_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_MAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mextract_all_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_MAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-251-1fec518517af>\u001b[0m in \u001b[0;36mextract_all_elements\u001b[0;34m(z_min, z_max)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_all_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_max\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mextract_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-252-6ce388b19c02>\u001b[0m in \u001b[0;36mextract_element\u001b[0;34m(Z)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misotope_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting {A}{element}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mextract_Igamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mextract_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-250-f216b4d40d35>\u001b[0m in \u001b[0;36mextract_Igamma\u001b[0;34m(A, element, Z)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msigm_ig_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0menergy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0msigm_energy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mig_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1796,'"
     ]
    }
   ],
   "source": [
    "download_range(Z_MIN, Z_MAX)\n",
    "parse_isotopes_range(Z_MIN,Z_MAX)\n",
    "download_all_elements(Z_MIN, Z_MAX)\n",
    "extract_all_elements(Z_MIN, Z_MAX)"
   ]
  }
 ]
}