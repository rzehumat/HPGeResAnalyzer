{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "590f3899dd7b9bcfd4cbc68d67e174e21f00fe45394f2e3932fd522000967c3f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_MIN = 1\n",
    "Z_MAX = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_isotopes_list(Z):\n",
    "    request_url = f\"http://nucleardata.nuclear.lu.se/toi/listnuc.asp?sql=&Z={Z}\"\n",
    "    urllib.request.urlretrieve(request_url, f\"downloads/find_isotopes/z_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        download_isotopes_list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_range(Z_MIN, Z_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_one(Z):\n",
    "    html_path = f\"downloads/find_isotopes/z_{Z}.html\"\n",
    "    isotopes_lst_html = open(html_path, \"r\")\n",
    "    bs = BeautifulSoup(isotopes_lst_html.read(), 'lxml')\n",
    "    table = bs.find_all(\"table\")[0]\n",
    "    nuclide_lst = table.find_all('th')[9:]\n",
    "    abbr = str(nuclide_lst[0].find('a')).split('</sup>')[1][:-4]\n",
    "    out_file_path = f\"downloads/find_isotopes_parsed/{Z}_{abbr}.txt\"\n",
    "    out_file = open(out_file_path, \"w\")\n",
    "    out_file.write(f\"{Z}\\n\")\n",
    "    out_file.write(f\"{abbr}\\n\")\n",
    "    for nuclide in nuclide_lst:\n",
    "        out_file.write(f\"{nuclide.find('sup').get_text()}\\n\")\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_isotopes_range(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        parse_isotopes_one(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_isotopes_range(Z_MIN,Z_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_isotopes(Z):\n",
    "    down_dir = \"downloads/find_isotopes_parsed\"\n",
    "    files_lst = os.listdir(down_dir)\n",
    "    file_name = [s for s in files_lst if str(Z) == s.split('_')[0]]\n",
    "    isotopes_lst_file = open(f\"{down_dir}/{file_name[0]}\", \"r\")\n",
    "    lines = isotopes_lst_file.readlines()\n",
    "    abbr = lines[1].strip()\n",
    "    A_lst = lines[2:]\n",
    "    for A in A_lst:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\"\n",
    "        urllib.request.urlretrieve(url, f\"downloads/isotopes_html/{A}_{abbr}_{Z}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Igamma(A, element, Z):\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "\n",
    "    try:\n",
    "        gammas_table = soup.find_all(\"table\")[4]\n",
    "        gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "    except:\n",
    "        A = int(A)\n",
    "        if A < 10:\n",
    "            str_A = '00' + str(A)\n",
    "        elif A < 100:\n",
    "            str_A = '0' + str(A)\n",
    "        print(colored(f\"Seems like there are no gamma-lines known for isotope {A}{element}.\", 'red'))\n",
    "        print(colored(\"Check yellow pages for reference.\", 'yellow'))\n",
    "        print(colored(f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={Z}0{str_A}\", 'yellow'))\n",
    "        return 1\n",
    "    energy = []\n",
    "    sigm_energy = []\n",
    "    i = []\n",
    "    sigm_i = []\n",
    "\n",
    "    for row in gammas_rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        e_val = cells[0].get_text(strip=True)\n",
    "        i_val = cells[1].get_text(strip=True)\n",
    "        try:\n",
    "            ig_val = float(i_val[:-1])\n",
    "            sigm_ig_val = float(i_val[-1])\n",
    "        except:\n",
    "            ig_val = float('NaN')\n",
    "            sigm_ig_val = float('NaN')\n",
    "       \n",
    "        energy.append(float(e_val[:-1]))\n",
    "        sigm_energy.append(int(e_val[-1]))\n",
    "        i.append(ig_val)\n",
    "        \n",
    "        sigm_i.append(sigm_ig_val)\n",
    "\n",
    "\n",
    "    df_dict = {\n",
    "        \"E_tab\": energy,\n",
    "        \"sigm_E\": sigm_energy, \n",
    "        \"Ig\": i,\n",
    "        \"sigm_Ig\": sigm_i\n",
    "        }\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df_name = f'downloads/ig_db/{A}{element}.csv'\n",
    "    df.to_csv(df_name)\n",
    "   \n",
    "    print(f\"Ig extracted from file 'downloads/{A}{element}.html' into '{df_name}'.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_elements(z_min, z_max):\n",
    "    for Z in range(z_min, z_max + 1):\n",
    "        extract_element(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_element(Z):\n",
    "    html_lst = os.listdir(\"downloads/isotopes_html\")\n",
    "    element_files = [f for f in html_lst if str(Z) == f.split('_')[-1].split('.')[0]]\n",
    "    for isotope_file in element_files:\n",
    "        A, element, Z = (isotope_file.split('.')[0]).split('_')\n",
    "        extract_Igamma(A, element, Z)\n",
    "        extract_info(A, element, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(A, element, ):\n",
    "    html_file = open(f\"downloads/isotopes_html/{A}_{element}_{Z}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    table = soup.find_all(\"table\")[0]\n",
    "\n",
    "    info_rows = table.find_all(\"tr\")[6:16]\n",
    "    info_df = {}\n",
    "    for row in info_rows:\n",
    "        key = (row.find_all(\"th\")[0]).get_text(strip=True)\n",
    "        val = row.find_all(\"td\")[0]\n",
    "        if val.find(\"i\"):\n",
    "            sigm = val.find(\"i\").get_text(strip=True)\n",
    "            val = str(val.get_text(strip=True))[:-len(sigm)]\n",
    "            info_df[f\"sigm_{key}\"] = sigm\n",
    "        else:\n",
    "            val = val.get_text(strip=True)\n",
    "\n",
    "        info_df[key] = val\n",
    "    \n",
    "    info_df.pop('', None)\n",
    "    info_df = pd.DataFrame(info_df, index=[0])\n",
    "\n",
    "    columns = info_df.columns.tolist()\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i][:-1]\n",
    "        columns[i] = (columns[i]).replace(u'\\xa0', u' ')\n",
    "\n",
    "    info_df.columns = columns\n",
    "    info_df[\"Literature cut-off date\"] = pd.to_datetime(info_df[\"Literature cut-off date\"])\n",
    "\n",
    "    for mode in re.findall('[A-Z][^A-Z]*', str(info_df[\"Prod. mode\"][0])):\n",
    "        mode = mode.replace(u'\\xa0', u' ')\n",
    "        info_df[f\"Prod_mode_{mode}\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = open(f\"downloads/isotopes_html/14_C_6.html\", \"r\")\n",
    "soup = BeautifulSoup(html_file.read(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  sigm_Half life Half life  Jp  Sn(keV) sigm_Sp(keV)  Sp(keV)  \\\n",
       "0             40    5730 y  0+  8176.44           11  20831.3   \n",
       "\n",
       "                                          Prod. mode    ENSDF citation  \\\n",
       "0  Naturally occurringFast neutron activationTher...  NP A523,1 (1991)   \n",
       "\n",
       "  Literature cut-off date            Author(s)      References since cut-off  \\\n",
       "0              1986-04-23  F. Ajzenberg-Selove  14C decay from 1986-98 (NSR)   \n",
       "\n",
       "   Prod_mode_Naturally occurring  Prod_mode_Fast neutron activation  \\\n",
       "0                           True                               True   \n",
       "\n",
       "   Prod_mode_Thermal neutron activation  \n",
       "0                                  True  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sigm_Half life</th>\n      <th>Half life</th>\n      <th>Jp</th>\n      <th>Sn(keV)</th>\n      <th>sigm_Sp(keV)</th>\n      <th>Sp(keV)</th>\n      <th>Prod. mode</th>\n      <th>ENSDF citation</th>\n      <th>Literature cut-off date</th>\n      <th>Author(s)</th>\n      <th>References since cut-off</th>\n      <th>Prod_mode_Naturally occurring</th>\n      <th>Prod_mode_Fast neutron activation</th>\n      <th>Prod_mode_Thermal neutron activation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>5730 y</td>\n      <td>0+</td>\n      <td>8176.44</td>\n      <td>11</td>\n      <td>20831.3</td>\n      <td>Naturally occurringFast neutron activationTher...</td>\n      <td>NP A523,1 (1991)</td>\n      <td>1986-04-23</td>\n      <td>F. Ajzenberg-Selove</td>\n      <td>14C decay from 1986-98 (NSR)</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "table = soup.find_all(\"table\")[0]\n",
    "info_rows = table.find_all(\"tr\")[6:16]\n",
    "\n",
    "#info_df = pd.DataFrame()\n",
    "info_df = {}\n",
    "for row in info_rows:\n",
    "    key = (row.find_all(\"th\")[0]).get_text(strip=True)\n",
    "    val = row.find_all(\"td\")[0]\n",
    "    #print(val)\n",
    "    if val.find(\"i\"):\n",
    "        sigm = val.find(\"i\").get_text(strip=True)\n",
    "        val = str(val.get_text(strip=True))[:-len(sigm)]\n",
    "        info_df[f\"sigm_{key}\"] = sigm\n",
    "    else:\n",
    "        val = val.get_text(strip=True)\n",
    "\n",
    "    info_df[key] = val\n",
    "info_df.pop('', None)\n",
    "info_df = pd.DataFrame(info_df, index=[0])\n",
    "columns = info_df.columns.tolist()\n",
    "for i in range(len(columns)):\n",
    "    columns[i] = columns[i][:-1]\n",
    "    columns[i] = (columns[i]).replace(u'\\xa0', u' ')\n",
    "info_df.columns = columns\n",
    "info_df[\"Literature cut-off date\"] = pd.to_datetime(info_df[\"Literature cut-off date\"])\n",
    "\n",
    "for mode in re.findall('[A-Z][^A-Z]*', str(info_df[\"Prod. mode\"][0])):\n",
    "    mode = mode.replace(u'\\xa0', u' ')\n",
    "    info_df[f\"Prod_mode_{mode}\"] = True\n",
    "\n",
    "#info_df[\"Half_life\"] = to_seconds(info_df[\"Half_life\"])\n",
    "\n",
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in re.findall('[A-Z][^A-Z]*', str(info_df[\"Prod. mode\"][0])):\n",
    "    mode = mode.replace(u'\\xa0', u' ')\n",
    "    info_df[f\"Prod_mode_{mode}\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['sigm_Half life',\n",
       " 'Half life',\n",
       " 'Jp',\n",
       " 'Sn(keV)',\n",
       " 'sigm_Sp(keV)',\n",
       " 'Sp(keV)',\n",
       " 'Prod. mode',\n",
       " 'ENSDF citation',\n",
       " 'Literature cut-off date',\n",
       " 'Author(s)',\n",
       " 'References since cut-off',\n",
       " 'Prod_mode_Naturally occurring',\n",
       " 'Prod_mode_Fast neutron activation',\n",
       " 'Prod_mode_Thermal neutron activation']"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "info_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "str1 = \"foobar\"\n",
    "str2 = \"bar\"\n",
    "print(str1[:-len(str2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[31mSeems like there are no gamma-lines known for isotope 5Be.\u001b[0m\n\u001b[33mCheck yellow pages for reference.\u001b[0m\n\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40005\u001b[0m\nIg extracted from file 'downloads/14Be.html' into 'downloads/ig_db/14Be.csv'.\n\u001b[31mSeems like there are no gamma-lines known for isotope 8Be.\u001b[0m\n\u001b[33mCheck yellow pages for reference.\u001b[0m\n\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40008\u001b[0m\nIg extracted from file 'downloads/7Be.html' into 'downloads/ig_db/7Be.csv'.\n\u001b[31mSeems like there are no gamma-lines known for isotope 12Be.\u001b[0m\n\u001b[33mCheck yellow pages for reference.\u001b[0m\n\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40012\u001b[0m\n\u001b[31mSeems like there are no gamma-lines known for isotope 6Be.\u001b[0m\n\u001b[33mCheck yellow pages for reference.\u001b[0m\n\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40006\u001b[0m\n\u001b[31mSeems like there are no gamma-lines known for isotope 13Be.\u001b[0m\n\u001b[33mCheck yellow pages for reference.\u001b[0m\n\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40013\u001b[0m\n\u001b[31mSeems like there are no gamma-lines known for isotope 10Be.\u001b[0m\n\u001b[33mCheck yellow pages for reference.\u001b[0m\n\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40010\u001b[0m\nIg extracted from file 'downloads/11Be.html' into 'downloads/ig_db/11Be.csv'.\n\u001b[31mSeems like there are no gamma-lines known for isotope 9Be.\u001b[0m\n\u001b[33mCheck yellow pages for reference.\u001b[0m\n\u001b[33mhttp://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA=40009\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "extract_Igamma_element(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ig extracted from file 'downloads/20F.html' into 'downloads/ig_db/20F.csv'.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "extract_Igamma(20, \"F\", 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    download_all_isotopes(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = [s for s in lst if \"12\" == s.split('_')[0]]"
   ]
  }
 ]
}