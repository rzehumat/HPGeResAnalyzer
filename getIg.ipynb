{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_unknown(file, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_isotope(measured_df, mat_list, hl_min, hl_max, name):\n",
    "    precursores = mat_list.split(',')\n",
    "    isotopes = []\n",
    "    with open(\"database/irr_products.json\") as f:\n",
    "        irradiation_products = json.load(f)\n",
    "    \n",
    "    for precursor in precursores:\n",
    "        try:\n",
    "            isotopes += irradiation_products[precursor]\n",
    "        \n",
    "        except:\n",
    "            irradiation_products[precursor] = load_irr_prod(precursor)\n",
    "            with open(\"database/irr_products.json\", 'w') as json_out:\n",
    "                json.dump(irradiation_products, json_out)\n",
    "\n",
    "    # get unique only\n",
    "    isotopes = list(set(isotopes))\n",
    "\n",
    "    db_parameters = [\"half-life\", \"sigm_half-life\", \"lambda\", \"sigm_lambda\", \"isotope\", \"Ig\", \"sigm_Ig\", \"E_tab\", \"sigm_E_tab\"]\n",
    "\n",
    "    measured_df[[db_parameters]] = np.nan*np.ones(shape=(measured_df.shape[0], len(db_parameters)))\n",
    "\n",
    "    for isotope in isotopes:\n",
    "        measured_df = add_db_info(measured_df, isotope)\n",
    "    \n",
    "    measured_df.to_csv(f\"out/{name}wDBinfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_nat_element(file, mat_list, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_element_spec(file, mat_list, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_material(file, mat_list, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_Igamma(file, material, hl_min, hl_max):\n",
    "#    df = pd.read_csv(file,header=0,index_col=0)\n",
    "#    name = file.split('.')[0]\n",
    "#    mat_type, mat_list = material.split(',', maxindex=1)\n",
    "#    switcher = {\n",
    "#        0: ig_unknown(df, hl_min, hl_max, name),\n",
    "#        \"isotope\": ig_isotope(df, mat_list, hl_min, hl_max, name), \n",
    "#        \"element_natural\": ig_nat_element(df, mat_list, hl_min, hl_max, name),\n",
    "#        \"element_spec\": ig_spec_element(df, mat_list, hl_min, hl_max, name),\n",
    "#        \"material\": ig_material(df, mat_list, hl_min, hl_max, name)\n",
    "#    }\n",
    "#    switcher.get(mat_type, \"Invalid material given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_Igamma_dir(parsed_dir):\n",
    "    if not os.path.isdir(parsed_dir):\n",
    "        raise Exception(f\"Directory '{parsed_dir}' not found. Consider creating it and moving parsed files there.\")\n",
    "\n",
    "    Path(\"./reports_Ig\").mkdir(parents=True, exist_ok=True)\n",
    "    for parsed_file in glob.iglob(f\"{parsed_dir}/*.csv\"):\n",
    "        append_Igamma(parsed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_Igamma(file):\n",
    "    print(file)\n",
    "    A, element = re.split(r'(\\d+)(\\w+)', file)[-3:-1]\n",
    "    print(A)\n",
    "    print(element)\n",
    "\n",
    "    Path(\"./ig_db\").mkdir(parents=True, exist_ok=True)\n",
    "    if os.path.isfile(f\"ig_db/{A}{element}.csv\"):\n",
    "        #ig_df = pd.read_csv(f\"ig_db/{ig_file_name}\", header=None, index_col=None)\n",
    "        print(\"Reading the csv with gammas.\")\n",
    "    else:\n",
    "        Path(\"./downloads\").mkdir(parents=True, exist_ok=True)\n",
    "        if os.path.isfile(f\"downloads/{A}{element}.html\"):\n",
    "            extract_Igamma(A, element)\n",
    "            #ig_df = pd.read_csv(f\"ig_db/{ig_file_name}\", header=None, index_col=None)\n",
    "            print(\"Reading the csv with gammas.\")\n",
    "        else:\n",
    "            download(A, element)\n",
    "            extract_Igamma(A, element)\n",
    "            #ig_df = pd.read_csv(f\"ig_db/{ig_file_name}\", header=None, index_col=None)\n",
    "            print(\"Reading the csv with gammas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZ(element):\n",
    "    element_Z ={\n",
    "        \"U\": 92,\n",
    "        \"Pu\": 94\n",
    "    }\n",
    "    return element_Z[element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(A, element):\n",
    "    #Path(f'downloads/{A}{element}.html').touch()\n",
    "    url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={getZ(element)}0{A}\"\n",
    "    urllib.request.urlretrieve (url, f\"downloads/{A}{element}.html\")\n",
    "    print(f\"File {A}{element}.html downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Igamma(A, element):\n",
    "    html_file = f\"downloads/{A}{element}.html\"\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    \n",
    "    gammas_table = soup.find_all(\"table\")[4]\n",
    "    gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "    energy = []\n",
    "    sigm_energy = []\n",
    "    i = []\n",
    "    sigm_i = []\n",
    "\n",
    "    for row in gammas_rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        e_val = float(cells[0].get_text(strip=True))\n",
    "        i_val = float(cells[1].get_text(strip=True))\n",
    "        \n",
    "        energy.append(e_val[:-1])\n",
    "        sigm_energy.append(e_val[-1])\n",
    "        i_list.append(i_val[:-1])\n",
    "        sigm_i.append(i_val[-1])\n",
    "\n",
    "\n",
    "    \n",
    "    #file = open(f\"downloads/{A}{element}.html\", 'r')\n",
    "    #copy_line = False\n",
    "    #gamma_lines = []\n",
    "    #for line in file.readlines():\n",
    "    #    if \"A NAME=\\\"g\\\"\" in line:\n",
    "    #        copy_line = True\n",
    "    #        continue\n",
    "    #    if copy_line:\n",
    "    #        gamma_lines.append(line)\n",
    "    #    \n",
    "    #    if \"A NAME=\\\"x\\\"\" in line:\n",
    "    #        break\n",
    "    #    \n",
    "    #file.close()\n",
    "\n",
    "    with open(f\"ig_db/{A}{element}.csv\", \"w\") as f:\n",
    "        for ig in gamma_lines:\n",
    "            f.write(f\"{ig}\\n\")\n",
    "        f.close()\n",
    "    print(f\"Ig extracted from file 'downloads/{A}{element}.html' into 'ig_db/{A}{element}.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['49.556', '113.51']\n['0.064\\xa08\\xa0', '0.0102\\xa015\\xa0']\n"
     ]
    }
   ],
   "source": [
    "html_doc = open(\"downloads/238U.html\", \"r\")\n",
    "\n",
    "soup = BeautifulSoup(html_doc.read(), 'lxml')\n",
    "gammas_table = soup.find_all(\"table\")[4]\n",
    "gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "gamma_energy_list = []\n",
    "gamma_i_list = []\n",
    "\n",
    "for row in gammas_rows:\n",
    "    cells = row.find_all('td')\n",
    "    e_val = cells[0].get_text(strip=True)\n",
    "\n",
    "    gamma_energy_list.append(e_val)\n",
    "    gamma_i_list.append(cells[1].get_text(strip=False))\n",
    "\n",
    "\n",
    "print(gamma_energy_list)\n",
    "print(gamma_i_list)\n",
    "\n",
    "#print(html_doc.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "parsed_reports/238U.csv\n238\nU\nIg extracted from file 'downloads/238U.html' into 'ig_db/238U.csv'.\nReading the csv with gammas.\nparsed_reports/239Pu.csv\n239\nPu\nIg extracted from file 'downloads/239Pu.html' into 'ig_db/239Pu.csv'.\nReading the csv with gammas.\n"
     ]
    }
   ],
   "source": [
    "append_Igamma_dir(\"parsed_reports\")"
   ]
  }
 ]
}