{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_unknown(file, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_isotope(measured_df, mat_list, hl_min, hl_max, name):\n",
    "    precursores = mat_list.split(',')\n",
    "    isotopes = []\n",
    "    with open(\"database/irr_products.json\") as f:\n",
    "        irradiation_products = json.load(f)\n",
    "    \n",
    "    for precursor in precursores:\n",
    "        try:\n",
    "            isotopes += irradiation_products[precursor]\n",
    "        \n",
    "        except:\n",
    "            irradiation_products[precursor] = load_irr_prod(precursor)\n",
    "            with open(\"database/irr_products.json\", 'w') as json_out:\n",
    "                json.dump(irradiation_products, json_out)\n",
    "\n",
    "    # get unique only\n",
    "    isotopes = list(set(isotopes))\n",
    "\n",
    "    db_parameters = [\"half-life\", \"sigm_half-life\", \"lambda\", \"sigm_lambda\", \"isotope\", \"Ig\", \"sigm_Ig\", \"E_tab\", \"sigm_E_tab\"]\n",
    "\n",
    "    measured_df[[db_parameters]] = np.nan*np.ones(shape=(measured_df.shape[0], len(db_parameters)))\n",
    "\n",
    "    for isotope in isotopes:\n",
    "        measured_df = add_db_info(measured_df, isotope)\n",
    "    \n",
    "    measured_df.to_csv(f\"out/{name}wDBinfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_nat_element(file, mat_list, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_element_spec(file, mat_list, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_material(file, mat_list, hl_min, hl_max):\n",
    "    return \"Feature not implemented yet. Write an issue to GitHub.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_Igamma(file, material, hl_min, hl_max):\n",
    "#    df = pd.read_csv(file,header=0,index_col=0)\n",
    "#    name = file.split('.')[0]\n",
    "#    mat_type, mat_list = material.split(',', maxindex=1)\n",
    "#    switcher = {\n",
    "#        0: ig_unknown(df, hl_min, hl_max, name),\n",
    "#        \"isotope\": ig_isotope(df, mat_list, hl_min, hl_max, name), \n",
    "#        \"element_natural\": ig_nat_element(df, mat_list, hl_min, hl_max, name),\n",
    "#        \"element_spec\": ig_spec_element(df, mat_list, hl_min, hl_max, name),\n",
    "#        \"material\": ig_material(df, mat_list, hl_min, hl_max, name)\n",
    "#    }\n",
    "#    switcher.get(mat_type, \"Invalid material given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_Igamma_dir(parsed_dir):\n",
    "    if not os.path.isdir(parsed_dir):\n",
    "        raise Exception(f\"Directory '{parsed_dir}' not found. Consider creating it and moving parsed files there.\")\n",
    "\n",
    "    Path(\"./reports_Ig\").mkdir(parents=True, exist_ok=True)\n",
    "    for parsed_file in glob.iglob(f\"{parsed_dir}/*.csv\"):\n",
    "        append_Igamma(parsed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_Igamma(file):\n",
    "    print(file)\n",
    "    A, element = re.split(r'(\\d+)(\\w+)', file)[-3:-1]\n",
    "    print(A)\n",
    "    print(element)\n",
    "\n",
    "    Path(\"./ig_db\").mkdir(parents=True, exist_ok=True)\n",
    "    if os.path.isfile(f\"ig_db/{A}{element}.csv\"):\n",
    "        ig_df = pd.read_csv(f\"ig_db/{A}{element}.csv\", header=0, index_col=0)\n",
    "        print(\"Reading the csv with gammas.\")\n",
    "    else:\n",
    "        Path(\"./downloads\").mkdir(parents=True, exist_ok=True)\n",
    "        if os.path.isfile(f\"downloads/{A}{element}.html\"):\n",
    "            extract_Igamma(A, element)\n",
    "            ig_df = pd.read_csv(f\"ig_db/{A}{element}.csv\", header=0, index_col=0)\n",
    "            print(\"Reading the csv with gammas.\")\n",
    "        else:\n",
    "            download(A, element)\n",
    "            extract_Igamma(A, element)\n",
    "            ig_df = pd.read_csv(f\"ig_db/{A}{element}.csv\", header=0, index_col=0)\n",
    "            print(\"Reading the csv with gammas.\")\n",
    "    \n",
    "    parsed_df = pd.read_csv(file, index_col=0)\n",
    "    joined_df = add_Ig(parsed_df, ig_df)\n",
    "    \n",
    "    Path(\"./with_Ig\").mkdir(parents=True, exist_ok=True)\n",
    "    joined_df.to_csv(f\"with_Ig/{A}{element}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_Ig(df, ig):\n",
    "    e_col = []\n",
    "    ig_col = []\n",
    "\n",
    "    a = np.empty((df.shape[0], 2))\n",
    "    a[:] = np.nan\n",
    "    df[[\"Energy_table\", \"Ig\"]] = a\n",
    "    # UGLY, never for-loop in pandas\n",
    "    for row_no in range(df.shape[0]):\n",
    "        for ig_row_no in range(ig.shape[0]):\n",
    "            if (df[[\"Energy\"]] - df[[\"FWHM\"]]).iloc[row_no].to_numpy() > ig[[\"E\"]].iloc[ig_row_no].to_numpy():\n",
    "                continue\n",
    "            elif (df[[\"Energy\"]] + df[[\"FWHM\"]]).iloc[row_no] < ig[[\"E\"]].iloc[ig_row_no]:\n",
    "                break\n",
    "            else:\n",
    "                df[[\"Energy_table\", \"Ig\"]].iloc[row_no,:] = ig[[\"E\", \"Ig\"]].iloc[ig_row_no, :]\n",
    "                ig = ig.drop(ig.index[0:ig_row_no])\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             E  sigm_E            Ig  sigm_Ig\n",
       "0       0.0768       5           NaN      NaN\n",
       "1      12.9630       2           NaN      NaN\n",
       "2      30.0370       3  2.170000e-04      6.0\n",
       "3      38.6610       2  1.050000e-02      2.0\n",
       "4      40.4100       5  1.621000e-04      6.0\n",
       "..         ...     ...           ...      ...\n",
       "198   986.9100       4  2.100000e-08      4.0\n",
       "199   992.6400       3  2.700000e-08      4.0\n",
       "200  1005.8000       2  1.800000e-08      3.0\n",
       "201  1009.4000       3  1.400000e-08      3.0\n",
       "202  1057.4000       2  4.500000e-08      7.0\n",
       "\n",
       "[203 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>E</th>\n      <th>sigm_E</th>\n      <th>Ig</th>\n      <th>sigm_Ig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0768</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.9630</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30.0370</td>\n      <td>3</td>\n      <td>2.170000e-04</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>38.6610</td>\n      <td>2</td>\n      <td>1.050000e-02</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40.4100</td>\n      <td>5</td>\n      <td>1.621000e-04</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>986.9100</td>\n      <td>4</td>\n      <td>2.100000e-08</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>992.6400</td>\n      <td>3</td>\n      <td>2.700000e-08</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>1005.8000</td>\n      <td>2</td>\n      <td>1.800000e-08</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>1009.4000</td>\n      <td>3</td>\n      <td>1.400000e-08</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>1057.4000</td>\n      <td>2</td>\n      <td>4.500000e-08</td>\n      <td>7.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>203 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "parsed_df = pd.read_csv(\"parsed_reports/239Pu.csv\", index_col=0)\n",
    "parsed_df[[\"Energy\", \"FWHM\"]]\n",
    "ig_df = pd.read_csv(f\"ig_db/239Pu.csv\", header=0, index_col=0)\n",
    "ig_df\n",
    "#for row in parsed_df[[\"Energy\", \"FWHM\"]]:\n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZ(element):\n",
    "    element_Z ={\n",
    "        \"U\": 92,\n",
    "        \"Pu\": 94\n",
    "    }\n",
    "    return element_Z[element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(A, element):\n",
    "    url = f\"http://nucleardata.nuclear.lu.se/toi/nuclide.asp?iZA={getZ(element)}0{A}\"\n",
    "    urllib.request.urlretrieve (url, f\"downloads/{A}{element}.html\")\n",
    "    print(f\"File {A}{element}.html downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Igamma(A, element):\n",
    "    html_file = open(f\"downloads/{A}{element}.html\", \"r\")\n",
    "    soup = BeautifulSoup(html_file.read(), 'lxml')\n",
    "    \n",
    "    gammas_table = soup.find_all(\"table\")[4]\n",
    "    gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "    energy = []\n",
    "    sigm_energy = []\n",
    "    i = []\n",
    "    sigm_i = []\n",
    "\n",
    "    for row in gammas_rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        e_val = cells[0].get_text(strip=True)\n",
    "        i_val = cells[1].get_text(strip=True)\n",
    "        try:\n",
    "            ig_val = float(i_val[:-1])\n",
    "            sigm_ig_val = float(i_val[-1])\n",
    "        except:\n",
    "            ig_val = float('NaN')\n",
    "            sigm_ig_val = float('NaN')\n",
    "       \n",
    "        energy.append(float(e_val[:-1]))\n",
    "        sigm_energy.append(int(e_val[-1]))\n",
    "        i.append(ig_val)\n",
    "        \n",
    "        sigm_i.append(sigm_ig_val)\n",
    "\n",
    "\n",
    "    df_dict = {\n",
    "        \"E\": energy,\n",
    "        \"sigm_E\": sigm_energy, \n",
    "        \"Ig\": i,\n",
    "        \"sigm_Ig\": sigm_i\n",
    "        }\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df_name = f'ig_db/{A}{element}.csv'\n",
    "    df.to_csv(df_name)\n",
    "   \n",
    "    print(f\"Ig extracted from file 'downloads/{A}{element}.html' into '{df_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['49.55\\xa06\\xa0']\n['113.5\\xa01\\xa0']\n['49.55\\xa06\\xa0', '113.5\\xa01\\xa0']\n['0.064\\xa08\\xa0', '0.0102\\xa015\\xa0']\n"
     ]
    }
   ],
   "source": [
    "html_doc = open(\"downloads/238U.html\", \"r\")\n",
    "\n",
    "soup = BeautifulSoup(html_doc.read(), 'lxml')\n",
    "gammas_table = soup.find_all(\"table\")[4]\n",
    "gammas_rows = gammas_table.find_all('tr')[3:-1]\n",
    "gamma_energy_list = []\n",
    "gamma_i_list = []\n",
    "\n",
    "for row in gammas_rows:\n",
    "    cells = row.find_all('td')\n",
    "    e_val = cells[0].get_text()\n",
    "    print(re.split(r'\\\\', e_val))\n",
    "\n",
    "    gamma_energy_list.append(e_val)\n",
    "    gamma_i_list.append(cells[1].get_text(strip=False))\n",
    "\n",
    "\n",
    "print(gamma_energy_list)\n",
    "print(gamma_i_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "parsed_reports/238U.csv\n238\nU\nReading the csv with gammas.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-233ad86a88f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mappend_Igamma_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parsed_reports\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-961a22177d99>\u001b[0m in \u001b[0;36mappend_Igamma_dir\u001b[0;34m(parsed_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./reports_Ig\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparsed_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{parsed_dir}/*.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mappend_Igamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-ce09e6b59d8d>\u001b[0m in \u001b[0;36mappend_Igamma\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mparsed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mjoined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_Ig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mig_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./with_Ig\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-7294e93dd490>\u001b[0m in \u001b[0;36madd_Ig\u001b[0;34m(df, ig)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mig_row_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Energy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FWHM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"E\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mig_row_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Energy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FWHM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_no\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"E\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mig_row_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "append_Igamma_dir(\"parsed_reports\")"
   ]
  }
 ]
}